{"path":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","commits":[{"id":"e15199583d3635cb940942caed05132dd6c4c7c6","date":1424875551,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,int,String,String,String,int,int,boolean,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect\n                  .getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    register(descriptor.getName(), descriptor, true, true);\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientTimeout, int zkClientConnectTimeout, String localHost, String locaHostPort,\n                      String localHostContext, int leaderVoteWait, int leaderConflictResolveWait, boolean genericCoreNodeNames, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n    this.genericCoreNodeNames = genericCoreNodeNames;\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    localHostContext = trimLeadingAndTrailingSlashes(localHostContext);\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = locaHostPort;\n    this.localHostContext = localHostContext;\n    this.hostName = normalizeHostName(localHost);\n    this.nodeName = generateNodeName(this.hostName,\n        this.localHostPort,\n        this.localHostContext);\n\n    this.leaderVoteWait = leaderVoteWait;\n    this.leaderConflictResolveWait = leaderConflictResolveWait;\n\n    this.clientTimeout = zkClientTimeout;\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cc.getConfig().getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cc.getConfig().getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, zkClientTimeout,\n        zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect\n                  .getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    register(descriptor.getName(), descriptor, true, true);\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(zkClientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"/dev/null","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect\n                  .getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    register(descriptor.getName(), descriptor, true, true);\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3c3931df936f937d0001d9fda9ead62f8599479","date":1429011920,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    MDC.put(NODE_NAME_PROP, nodeName);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect\n                  .getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    register(descriptor.getName(), descriptor, true, true);\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect\n                  .getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    register(descriptor.getName(), descriptor, true, true);\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d92f2aa7a6efa1c4b8f9984131aa94d9729ff92a","date":1431710266,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    MDC.put(NODE_NAME_PROP, nodeName);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    MDC.put(NODE_NAME_PROP, nodeName);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect\n                  .getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    register(descriptor.getName(), descriptor, true, true);\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":["29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"439c63ae5d22132fca810a0029a854e97d2c1a3e","date":1432733612,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n\n    MDC.put(NODE_NAME_PROP, nodeName);\n\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6bdcb86c29922edae9a14852e636303bc52df094","date":1438887454,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient);\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2209af2c265d2258ec4b29c8cc78622d36994a15","date":1440641916,"type":3,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064","date":1441124018,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    leaderElector = new LeaderElector(zkClient);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05b08348be52bb628b319cfd65cd2691a6edf8be","date":1456253944,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":["bbb0b5c5101d175049b4ced1462f4c266d32fc63"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a5296efc4b319f5647b606629c093a94b23692c6","date":1456267155,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","date":1456306182,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19498030e0adab22f604f935cae3c03dcf0952a6","date":1456558851,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"10bdc820112adba1fe274124a0b60b7bca24d9d2","date":1456780149,"type":3,"author":"Mark Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"af2638813028b254a88b418ebeafb541afb49653","date":1456804822,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getInQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, new Runnable() {\n      @Override\n      public void run() {\n        if(cc!=null) cc.securityNodeChanged();\n      }\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3","date":1460654262,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              if (descriptors != null) {\n                ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              synchronized (reconnectListeners) {\n                for (OnReconnect listener : reconnectListeners) {\n                  try {\n                    listener.command();\n                  } catch (Exception exc) {\n                    // not much we can do here other than warn in the log\n                    log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                  }\n                }\n              }\n\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":["1596015c8bad249c0b9a52182de1d47e1d56fdde","531fe719c7218235a679452eb3d137bfd8fc6af1","d92f2aa7a6efa1c4b8f9984131aa94d9729ff92a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"115923bc88e5b1dc4bef049b1ded8486723052ed","date":1463216796,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d528fd7ae22865015b756e0a03832e2051de2a9c","date":1476721105,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    this.baseURL = zkStateReader.getBaseUrlForNodeName(this.nodeName);\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e5195d9b6757fc3b49ce0b0d98e9616bfeaa09f","date":1486929486,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d21dace9d18b198721b5f6835adb37c57acd5d20","date":1487384563,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac","date":1503580177,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b869898f50ca80263bac2e3ae0949f7700e5c977","date":1503580229,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85212dad4ed576c7f7e6c165ee19e597b7b4efc8","date":1507997740,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84f20f331d8001864545c7021812d8c6509c7593","date":1517216128,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    cmdExecutor = new ZkCmdExecutor(clientTimeout);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dd8a9ad1acc754f713e220250044c2bf06a22a0b","date":1518740056,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider);\n\n    this.overseerJobQueue = Overseer.getStateUpdateQueue(zkClient);\n    this.overseerCollectionQueue = Overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = Overseer.getConfigSetQueue(zkClient);\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":["531fe719c7218235a679452eb3d137bfd8fc6af1","849494cf2f3a96af5c8c84995108ddd8456fcd04","2209af2c265d2258ec4b29c8cc78622d36994a15","19498030e0adab22f604f935cae3c03dcf0952a6"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15","date":1554259533,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in \n    // solr.xml to indicate the root context, instead of hostContext=\"\" \n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n              \n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n    \n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"033183e9e2da4609614733f0226a38c88c49ed36","date":1557334549,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n    this.sysPropsCacher = new NodesSysPropsCacher(getSolrCloudManager().getNodeStateProvider(),\n        getNodeName(), zkStateReader);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bbb0b5c5101d175049b4ced1462f4c266d32fc63","date":1559534216,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() throws SessionExpiredException {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              // recreate our watchers first so that they exist even on any problems below\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n              \n              try {\n                registerAllCoresAsDown(registerOnReconnect, false);\n              } catch (SessionExpiredException e) {\n                // zk has to reconnect and this will all be tried again\n                throw e;\n              } catch (Exception e) {\n                // this is really best effort - in case of races or failure cases where we now need to be the leader, if anything fails,\n                // just continue\n                log.warn(\"Exception while trying to register all cores as DOWN\", e);\n              } \n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (SessionExpiredException e) {\n              throw e;\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n    this.sysPropsCacher = new NodesSysPropsCacher(getSolrCloudManager().getNodeStateProvider(),\n        getNodeName(), zkStateReader);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n\n              registerAllCoresAsDown(registerOnReconnect, false);\n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n    this.sysPropsCacher = new NodesSysPropsCacher(getSolrCloudManager().getNodeStateProvider(),\n        getNodeName(), zkStateReader);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":["05b08348be52bb628b319cfd65cd2691a6edf8be","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c560208bc8842ee884b76b08784ccb132f05b48","date":1585344697,"type":5,"author":"Mike","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,Supplier[List[CoreDescriptor]]).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#ZkController(CoreContainer,String,int,CloudConfig,CurrentCoreDescriptorProvider).mjava","sourceNew":"  /**\n   * @param cc Core container associated with this controller. cannot be null.\n   * @param zkServerAddress where to connect to the zk server\n   * @param zkClientConnectTimeout timeout in ms\n   * @param cloudConfig configuration for this controller. TODO: possibly redundant with CoreContainer\n   * @param descriptorsSupplier a supplier of the current core descriptors. used to know which cores to re-register on reconnect\n   */\n  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final Supplier<List<CoreDescriptor>> descriptorsSupplier)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() throws SessionExpiredException {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              // recreate our watchers first so that they exist even on any problems below\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n              \n              try {\n                registerAllCoresAsDown(descriptorsSupplier, false);\n              } catch (SessionExpiredException e) {\n                // zk has to reconnect and this will all be tried again\n                throw e;\n              } catch (Exception e) {\n                // this is really best effort - in case of races or failure cases where we now need to be the leader, if anything fails,\n                // just continue\n                log.warn(\"Exception while trying to register all cores as DOWN\", e);\n              } \n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = descriptorsSupplier.get();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (SessionExpiredException e) {\n              throw e;\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(descriptorsSupplier);\n        markAllAsNotLeader(descriptorsSupplier);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init();\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n    this.sysPropsCacher = new NodesSysPropsCacher(getSolrCloudManager().getNodeStateProvider(),\n        getNodeName(), zkStateReader);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","sourceOld":"  public ZkController(final CoreContainer cc, String zkServerAddress, int zkClientConnectTimeout, CloudConfig cloudConfig, final CurrentCoreDescriptorProvider registerOnReconnect)\n      throws InterruptedException, TimeoutException, IOException {\n\n    if (cc == null) throw new IllegalArgumentException(\"CoreContainer cannot be null.\");\n    this.cc = cc;\n\n    this.cloudConfig = cloudConfig;\n\n    this.genericCoreNodeNames = cloudConfig.getGenericCoreNodeNames();\n\n    // be forgiving and strip this off leading/trailing slashes\n    // this allows us to support users specifying hostContext=\"/\" in\n    // solr.xml to indicate the root context, instead of hostContext=\"\"\n    // which means the default of \"solr\"\n    String localHostContext = trimLeadingAndTrailingSlashes(cloudConfig.getSolrHostContext());\n\n    this.zkServerAddress = zkServerAddress;\n    this.localHostPort = cloudConfig.getSolrHostPort();\n    this.hostName = normalizeHostName(cloudConfig.getHost());\n    this.nodeName = generateNodeName(this.hostName, Integer.toString(this.localHostPort), localHostContext);\n    MDCLoggingContext.setNode(nodeName);\n    this.leaderVoteWait = cloudConfig.getLeaderVoteWait();\n    this.leaderConflictResolveWait = cloudConfig.getLeaderConflictResolveWait();\n\n    this.clientTimeout = cloudConfig.getZkClientTimeout();\n    DefaultConnectionStrategy strat = new DefaultConnectionStrategy();\n    String zkACLProviderClass = cloudConfig.getZkACLProviderClass();\n    ZkACLProvider zkACLProvider = null;\n    if (zkACLProviderClass != null && zkACLProviderClass.trim().length() > 0) {\n      zkACLProvider = cc.getResourceLoader().newInstance(zkACLProviderClass, ZkACLProvider.class);\n    } else {\n      zkACLProvider = new DefaultZkACLProvider();\n    }\n\n    String zkCredentialsProviderClass = cloudConfig.getZkCredentialsProviderClass();\n    if (zkCredentialsProviderClass != null && zkCredentialsProviderClass.trim().length() > 0) {\n      strat.setZkCredentialsToAddAutomatically(cc.getResourceLoader().newInstance(zkCredentialsProviderClass, ZkCredentialsProvider.class));\n    } else {\n      strat.setZkCredentialsToAddAutomatically(new DefaultZkCredentialsProvider());\n    }\n    addOnReconnectListener(getConfigDirListener());\n\n    zkClient = new SolrZkClient(zkServerAddress, clientTimeout, zkClientConnectTimeout, strat,\n        // on reconnect, reload cloud info\n        new OnReconnect() {\n\n          @Override\n          public void command() throws SessionExpiredException {\n            log.info(\"ZooKeeper session re-connected ... refreshing core states after session expiration.\");\n            clearZkCollectionTerms();\n            try {\n              // recreate our watchers first so that they exist even on any problems below\n              zkStateReader.createClusterStateWatchersAndUpdate();\n\n              // this is troublesome - we dont want to kill anything the old\n              // leader accepted\n              // though I guess sync will likely get those updates back? But\n              // only if\n              // he is involved in the sync, and he certainly may not be\n              // ExecutorUtil.shutdownAndAwaitTermination(cc.getCmdDistribExecutor());\n              // we need to create all of our lost watches\n\n              // seems we dont need to do this again...\n              // Overseer.createClientNodes(zkClient, getNodeName());\n\n              // start the overseer first as following code may need it's processing\n              if (!zkRunOnly) {\n                ElectionContext context = new OverseerElectionContext(zkClient,\n                    overseer, getNodeName());\n\n                ElectionContext prevContext = overseerElector.getContext();\n                if (prevContext != null) {\n                  prevContext.cancelElection();\n                  prevContext.close();\n                }\n\n                overseerElector.setup(context);\n                overseerElector.joinElection(context, true);\n              }\n\n              cc.cancelCoreRecoveries();\n              \n              try {\n                registerAllCoresAsDown(registerOnReconnect, false);\n              } catch (SessionExpiredException e) {\n                // zk has to reconnect and this will all be tried again\n                throw e;\n              } catch (Exception e) {\n                // this is really best effort - in case of races or failure cases where we now need to be the leader, if anything fails,\n                // just continue\n                log.warn(\"Exception while trying to register all cores as DOWN\", e);\n              } \n\n              // we have to register as live first to pick up docs in the buffer\n              createEphemeralLiveNode();\n\n              List<CoreDescriptor> descriptors = registerOnReconnect.getCurrentDescriptors();\n              // re register all descriptors\n              ExecutorService executorService = (cc != null) ? cc.getCoreZkRegisterExecutorService() : null;\n              if (descriptors != null) {\n                for (CoreDescriptor descriptor : descriptors) {\n                  // TODO: we need to think carefully about what happens when it\n                  // was\n                  // a leader that was expired - as well as what to do about\n                  // leaders/overseers\n                  // with connection loss\n                  try {\n                    // unload solrcores that have been 'failed over'\n                    throwErrorIfReplicaReplaced(descriptor);\n\n                    if (executorService != null) {\n                      executorService.submit(new RegisterCoreAsync(descriptor, true, true));\n                    } else {\n                      register(descriptor.getName(), descriptor, true, true, false);\n                    }\n                  } catch (Exception e) {\n                    SolrException.log(log, \"Error registering SolrCore\", e);\n                  }\n                }\n              }\n\n              // notify any other objects that need to know when the session was re-connected\n              HashSet<OnReconnect> clonedListeners;\n              synchronized (reconnectListeners) {\n                clonedListeners = (HashSet<OnReconnect>)reconnectListeners.clone();\n              }\n              // the OnReconnect operation can be expensive per listener, so do that async in the background\n              for (OnReconnect listener : clonedListeners) {\n                try {\n                  if (executorService != null) {\n                    executorService.submit(new OnReconnectNotifyAsync(listener));\n                  } else {\n                    listener.command();\n                  }\n                } catch (Exception exc) {\n                  // not much we can do here other than warn in the log\n                  log.warn(\"Error when notifying OnReconnect listener \" + listener + \" after session re-connected.\", exc);\n                }\n              }\n            } catch (InterruptedException e) {\n              // Restore the interrupted status\n              Thread.currentThread().interrupt();\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            } catch (SessionExpiredException e) {\n              throw e;\n            } catch (Exception e) {\n              SolrException.log(log, \"\", e);\n              throw new ZooKeeperException(\n                  SolrException.ErrorCode.SERVER_ERROR, \"\", e);\n            }\n          }\n\n        }, new BeforeReconnect() {\n\n      @Override\n      public void command() {\n        try {\n          ZkController.this.overseer.close();\n        } catch (Exception e) {\n          log.error(\"Error trying to stop any Overseer threads\", e);\n        }\n        closeOutstandingElections(registerOnReconnect);\n        markAllAsNotLeader(registerOnReconnect);\n      }\n    }, zkACLProvider, new ConnectionManager.IsClosed() {\n\n      @Override\n      public boolean isClosed() {\n        return cc.isShutDown();\n      }});\n\n\n    this.overseerRunningMap = Overseer.getRunningMap(zkClient);\n    this.overseerCompletedMap = Overseer.getCompletedMap(zkClient);\n    this.overseerFailureMap = Overseer.getFailureMap(zkClient);\n    this.asyncIdsMap = Overseer.getAsyncIdsMap(zkClient);\n\n    zkStateReader = new ZkStateReader(zkClient, () -> {\n      if (cc != null) cc.securityNodeChanged();\n    });\n\n    init(registerOnReconnect);\n\n    this.overseerJobQueue = overseer.getStateUpdateQueue();\n    this.overseerCollectionQueue = overseer.getCollectionQueue(zkClient);\n    this.overseerConfigSetQueue = overseer.getConfigSetQueue(zkClient);\n    this.sysPropsCacher = new NodesSysPropsCacher(getSolrCloudManager().getNodeStateProvider(),\n        getNodeName(), zkStateReader);\n\n    assert ObjectReleaseTracker.track(this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6bdcb86c29922edae9a14852e636303bc52df094":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"d92f2aa7a6efa1c4b8f9984131aa94d9729ff92a":["c3c3931df936f937d0001d9fda9ead62f8599479"],"d21dace9d18b198721b5f6835adb37c57acd5d20":["1e5195d9b6757fc3b49ce0b0d98e9616bfeaa09f"],"af2638813028b254a88b418ebeafb541afb49653":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","10bdc820112adba1fe274124a0b60b7bca24d9d2"],"2209af2c265d2258ec4b29c8cc78622d36994a15":["6bdcb86c29922edae9a14852e636303bc52df094"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["dd8a9ad1acc754f713e220250044c2bf06a22a0b"],"1ff4a3d0540c1b0f828f19adccd01d1b33c996a6":["6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064","a5296efc4b319f5647b606629c093a94b23692c6"],"84f20f331d8001864545c7021812d8c6509c7593":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"0ad30c6a479e764150a3316e57263319775f1df2":["29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3","115923bc88e5b1dc4bef049b1ded8486723052ed"],"05b08348be52bb628b319cfd65cd2691a6edf8be":["6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064"],"033183e9e2da4609614733f0226a38c88c49ed36":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"1e5195d9b6757fc3b49ce0b0d98e9616bfeaa09f":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["d92f2aa7a6efa1c4b8f9984131aa94d9729ff92a"],"e15199583d3635cb940942caed05132dd6c4c7c6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3","0ad30c6a479e764150a3316e57263319775f1df2"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e15199583d3635cb940942caed05132dd6c4c7c6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a5296efc4b319f5647b606629c093a94b23692c6":["6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064","05b08348be52bb628b319cfd65cd2691a6edf8be"],"bbb0b5c5101d175049b4ced1462f4c266d32fc63":["033183e9e2da4609614733f0226a38c88c49ed36"],"10bdc820112adba1fe274124a0b60b7bca24d9d2":["19498030e0adab22f604f935cae3c03dcf0952a6"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["d21dace9d18b198721b5f6835adb37c57acd5d20"],"1c560208bc8842ee884b76b08784ccb132f05b48":["bbb0b5c5101d175049b4ced1462f4c266d32fc63"],"c3c3931df936f937d0001d9fda9ead62f8599479":["e15199583d3635cb940942caed05132dd6c4c7c6"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["d21dace9d18b198721b5f6835adb37c57acd5d20"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064":["2209af2c265d2258ec4b29c8cc78622d36994a15"],"3a0c04b71951333291abc7f317109a6a5957bd28":["af2638813028b254a88b418ebeafb541afb49653"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3","d528fd7ae22865015b756e0a03832e2051de2a9c"],"dd8a9ad1acc754f713e220250044c2bf06a22a0b":["84f20f331d8001864545c7021812d8c6509c7593"],"19498030e0adab22f604f935cae3c03dcf0952a6":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6"],"115923bc88e5b1dc4bef049b1ded8486723052ed":["29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3":["3a0c04b71951333291abc7f317109a6a5957bd28"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1c560208bc8842ee884b76b08784ccb132f05b48"]},"commit2Childs":{"6bdcb86c29922edae9a14852e636303bc52df094":["2209af2c265d2258ec4b29c8cc78622d36994a15"],"d92f2aa7a6efa1c4b8f9984131aa94d9729ff92a":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"d21dace9d18b198721b5f6835adb37c57acd5d20":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac","85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"af2638813028b254a88b418ebeafb541afb49653":["3a0c04b71951333291abc7f317109a6a5957bd28"],"2209af2c265d2258ec4b29c8cc78622d36994a15":["6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15"],"1ff4a3d0540c1b0f828f19adccd01d1b33c996a6":["af2638813028b254a88b418ebeafb541afb49653","19498030e0adab22f604f935cae3c03dcf0952a6"],"84f20f331d8001864545c7021812d8c6509c7593":["dd8a9ad1acc754f713e220250044c2bf06a22a0b"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"05b08348be52bb628b319cfd65cd2691a6edf8be":["a5296efc4b319f5647b606629c093a94b23692c6"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["6bdcb86c29922edae9a14852e636303bc52df094"],"1e5195d9b6757fc3b49ce0b0d98e9616bfeaa09f":["d21dace9d18b198721b5f6835adb37c57acd5d20"],"033183e9e2da4609614733f0226a38c88c49ed36":["bbb0b5c5101d175049b4ced1462f4c266d32fc63"],"e15199583d3635cb940942caed05132dd6c4c7c6":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","c3c3931df936f937d0001d9fda9ead62f8599479"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e15199583d3635cb940942caed05132dd6c4c7c6","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"a5296efc4b319f5647b606629c093a94b23692c6":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6"],"10bdc820112adba1fe274124a0b60b7bca24d9d2":["af2638813028b254a88b418ebeafb541afb49653"],"bbb0b5c5101d175049b4ced1462f4c266d32fc63":["1c560208bc8842ee884b76b08784ccb132f05b48"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"c3c3931df936f937d0001d9fda9ead62f8599479":["d92f2aa7a6efa1c4b8f9984131aa94d9729ff92a"],"1c560208bc8842ee884b76b08784ccb132f05b48":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["84f20f331d8001864545c7021812d8c6509c7593"],"b869898f50ca80263bac2e3ae0949f7700e5c977":[],"6b18ef9cd3f6ff4f7733e6d43eebec259e0e9064":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","05b08348be52bb628b319cfd65cd2691a6edf8be","a5296efc4b319f5647b606629c093a94b23692c6"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["1e5195d9b6757fc3b49ce0b0d98e9616bfeaa09f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"3a0c04b71951333291abc7f317109a6a5957bd28":["29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"dd8a9ad1acc754f713e220250044c2bf06a22a0b":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"19498030e0adab22f604f935cae3c03dcf0952a6":["10bdc820112adba1fe274124a0b60b7bca24d9d2"],"115923bc88e5b1dc4bef049b1ded8486723052ed":["0ad30c6a479e764150a3316e57263319775f1df2"],"0db83f1bb855a4ac824c9a2a8e1ee9b29a039c15":["033183e9e2da4609614733f0226a38c88c49ed36"],"29e08b0fe8c5c0149b9e904e43afc1f270f8a6c3":["0ad30c6a479e764150a3316e57263319775f1df2","d470c8182e92b264680e34081b75e70a9f2b3c89","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","115923bc88e5b1dc4bef049b1ded8486723052ed"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b869898f50ca80263bac2e3ae0949f7700e5c977","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}