{"path":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","commits":[{"id":"0762b640e0d0d12b6edb96db68986e13145c3484","date":1307575932,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", Field.Store.YES, Field.Index.ANALYZED));\n    Fieldable repeatedField = newField(\"repeated\", \"second part of a repeated field\", Field.Store.YES, Field.Index.ANALYZED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", Field.Store.YES, Field.Index.ANALYZED));\n    Fieldable repeatedField = newField(\"repeated\", \"second part of a repeated field\", Field.Store.YES, Field.Index.ANALYZED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", Field.Store.YES, Field.Index.ANALYZED));\n    Fieldable repeatedField = newField(\"repeated\", \"second part of a repeated field\", Field.Store.YES, Field.Index.ANALYZED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", Field.Store.YES, Field.Index.ANALYZED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", Field.Store.YES, Field.Index.ANALYZED));\n    Fieldable repeatedField = newField(\"repeated\", \"second part of a repeated field\", Field.Store.YES, Field.Index.ANALYZED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", Field.Store.YES, Field.Index.ANALYZED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"53ae89cd75b0acbdfb8890710c6742f3fb80e65d","date":1315806626,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new ReusableAnalyzerBase() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2f49143da0a5d278a72f741432047fcfa6da996e","date":1316927425,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new ReusableAnalyzerBase() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    directory = newDirectory();\n    Analyzer analyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n      }\n\n      @Override\n      public int getPositionIncrementGap(String fieldName) {\n        return 100;\n      }\n    };\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, analyzer);\n    \n    Document doc = new Document();\n    doc.add(newField(\"field\", \"one two three four five\", TextField.TYPE_STORED));\n    doc.add(newField(\"repeated\", \"this is a repeated field - first part\", TextField.TYPE_STORED));\n    IndexableField repeatedField = newField(\"repeated\", \"second part of a repeated field\", TextField.TYPE_STORED);\n    doc.add(repeatedField);\n    doc.add(newField(\"palindrome\", \"one two three two one\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    \n    doc = new Document();\n    doc.add(newField(\"nonexist\", \"phrase exist notexist exist found\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = writer.getReader();\n    writer.close();\n\n    searcher = newSearcher(reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0762b640e0d0d12b6edb96db68986e13145c3484"],"0762b640e0d0d12b6edb96db68986e13145c3484":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["2f49143da0a5d278a72f741432047fcfa6da996e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0762b640e0d0d12b6edb96db68986e13145c3484"],"2f49143da0a5d278a72f741432047fcfa6da996e":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["0762b640e0d0d12b6edb96db68986e13145c3484"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["1509f151d7692d84fae414b2b799ac06ba60fcb4"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"0762b640e0d0d12b6edb96db68986e13145c3484":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","0762b640e0d0d12b6edb96db68986e13145c3484","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"2f49143da0a5d278a72f741432047fcfa6da996e":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["2f49143da0a5d278a72f741432047fcfa6da996e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}