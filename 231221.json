{"path":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":null,"sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"10d2f7af0975ac83900a2c970a62fe4c8667176b","date":1282358169,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    if (cmd.groupCommands != null) {\n      groupBy(qr, cmd);\n      return;\n    }\n\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3f7e3e91f914e6265ed09a3208cc60c9ba2a477d","date":1286157263,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    if (cmd.groupCommands != null) {\n      groupBy(qr, cmd);\n      return;\n    }\n\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    if (cmd.groupCommands != null) {\n      groupBy(qr, cmd);\n      return;\n    }\n\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4bf528aa2b9571ce1ec892ecf726201ef1e404e3","date":1288732150,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    if (cmd.groupCommands != null) {\n      groupBy(qr, cmd);\n      return;\n    }\n\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    if (cmd.groupCommands != null) {\n      groupBy(qr, cmd);\n      return;\n    }\n\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"090a0320e4de4a3674376aef96b9701f47564f86","date":1308707325,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","date":1309197122,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":["42f37a8cb4c5565e5233860fe796624f5ec2459f","42f37a8cb4c5565e5233860fe796624f5ec2459f","42f37a8cb4c5565e5233860fe796624f5ec2459f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset = null;\n\n    int flags = cmd.getFlags();\n    Query q = cmd.getQuery();\n    if (q instanceof ExtendedQuery) {\n      ExtendedQuery eq = (ExtendedQuery)q;\n      if (!eq.getCache()) {\n        flags |= (NO_CHECK_QCACHE | NO_SET_QCACHE | NO_CHECK_FILTERCACHE);\n      }\n    }\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null\n        && (flags & (NO_CHECK_QCACHE|NO_SET_QCACHE)) != ((NO_CHECK_QCACHE|NO_SET_QCACHE)))\n    {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(q, cmd.getFilterList(), cmd.getSort(), flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList().size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n      // If we are going to generate the result, bump up to the\n      // next resultWindowSize for better caching.\n\n      if ((flags & NO_SET_QCACHE) == 0) {\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n      } else {\n        key = null;  // we won't be caching the result\n      }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((flags & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      if (key != null) {\n        superset = out.docList;\n        out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n      }\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3f7e3e91f914e6265ed09a3208cc60c9ba2a477d":["10d2f7af0975ac83900a2c970a62fe4c8667176b"],"4bf528aa2b9571ce1ec892ecf726201ef1e404e3":["3f7e3e91f914e6265ed09a3208cc60c9ba2a477d"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"10d2f7af0975ac83900a2c970a62fe4c8667176b":["1da8d55113b689b06716246649de6f62430f15c0"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"85a883878c0af761245ab048babc63d099f835f3":["3f7e3e91f914e6265ed09a3208cc60c9ba2a477d","4bf528aa2b9571ce1ec892ecf726201ef1e404e3"],"2553b00f699380c64959ccb27991289aae87be2e":["4bf528aa2b9571ce1ec892ecf726201ef1e404e3","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["1da8d55113b689b06716246649de6f62430f15c0","4bf528aa2b9571ce1ec892ecf726201ef1e404e3"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["4bf528aa2b9571ce1ec892ecf726201ef1e404e3","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"090a0320e4de4a3674376aef96b9701f47564f86":["4bf528aa2b9571ce1ec892ecf726201ef1e404e3"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["090a0320e4de4a3674376aef96b9701f47564f86"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"3f7e3e91f914e6265ed09a3208cc60c9ba2a477d":["4bf528aa2b9571ce1ec892ecf726201ef1e404e3","85a883878c0af761245ab048babc63d099f835f3"],"4bf528aa2b9571ce1ec892ecf726201ef1e404e3":["85a883878c0af761245ab048babc63d099f835f3","2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","090a0320e4de4a3674376aef96b9701f47564f86"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"10d2f7af0975ac83900a2c970a62fe4c8667176b":["3f7e3e91f914e6265ed09a3208cc60c9ba2a477d"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"85a883878c0af761245ab048babc63d099f835f3":[],"2553b00f699380c64959ccb27991289aae87be2e":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"090a0320e4de4a3674376aef96b9701f47564f86":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"1da8d55113b689b06716246649de6f62430f15c0":["10d2f7af0975ac83900a2c970a62fe4c8667176b","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["c26f00b574427b55127e869b935845554afde1fa","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","a258fbb26824fd104ed795e5d9033d2d040049ee"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}