{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","commits":[{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7a8f6a0f831abdaf62496526336f43bbf7c5bbe","date":1352951976,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      // nocommit\n      perDocProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7cd329bd749496f6c58b586a6c0dd0dc8201206f","date":1353092226,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      // nocommit\n      simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      // nocommit\n      perDocProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f45457a742a53533c348c4b990b1c579ff364467","date":1353197071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      // nocommit shouldn't need null check:\n      if (codec.simpleDocValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      // nocommit\n      simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55eeb2534cd53d2a985669829df942468ebf5314","date":1354409119,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      // nocommit shouldn't need null check:\n      if (codec.simpleDocValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.simpleNormsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.simpleNormsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      // nocommit shouldn't need null check:\n      if (codec.simpleDocValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't need null check:\n      if (codec.simpleDocValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.simpleNormsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.simpleNormsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n      // nocommit shouldn't need null check:\n      if (codec.simpleDocValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.simpleNormsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.simpleNormsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200","date":1358521790,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't need null check:\n      if (codec.docValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.normsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't need null check:\n      if (codec.simpleDocValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.simpleDocValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.simpleNormsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.simpleNormsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46bf1a48fd33bf34430ade646b7dd67b984be2a8","date":1358725746,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't need null check:\n      assert codec.docValuesFormat() != null;\n      if (codec.docValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.normsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't need null check:\n      if (codec.docValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.normsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f06b860886fc48ea071171354835b8aed8a94de","date":1358789970,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't need null check:\n      assert codec.docValuesFormat() != null;\n      if (codec.docValuesFormat() != null) {\n        if (fieldInfos.hasDocValues()) {\n          simpleDVProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        } else {\n          simpleDVProducer = null;\n        }\n      } else {\n        simpleDVProducer = null;\n      }\n      // nocommit shouldn't need null check:\n      if (codec.normsFormat() != null) {\n        if (fieldInfos.hasNorms()) {\n          simpleNormsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        } else {\n          simpleNormsProducer = null;\n        }\n      } else {\n        simpleNormsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":["7b91922b55d15444d554721b352861d028eb8278","6aefa60f1ef9bec0dd4a76a2a23df98e2837a418"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":5,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context) throws IOException {\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n\n      if (fieldInfos.hasDocValues()) {\n        dvProducer = codec.docValuesFormat().fieldsProducer(segmentReadState);\n        assert dvProducer != null;\n      } else {\n        dvProducer = null;\n      }\n\n      if (fieldInfos.hasNorms()) {\n        normsProducer = codec.normsFormat().normsProducer(segmentReadState);\n        assert normsProducer != null;\n      } else {\n        normsProducer = null;\n      }\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8f06b860886fc48ea071171354835b8aed8a94de":["46bf1a48fd33bf34430ade646b7dd67b984be2a8"],"a45bec74b98f6fc05f52770cfb425739e6563960":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c7a8f6a0f831abdaf62496526336f43bbf7c5bbe":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"55eeb2534cd53d2a985669829df942468ebf5314":["f45457a742a53533c348c4b990b1c579ff364467"],"f45457a742a53533c348c4b990b1c579ff364467":["7cd329bd749496f6c58b586a6c0dd0dc8201206f"],"46bf1a48fd33bf34430ade646b7dd67b984be2a8":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9d153abcf92dc5329d98571a8c3035df9bd80648"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["0837ab0472feecb3a54260729d845f839e1cbd72"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","8f06b860886fc48ea071171354835b8aed8a94de"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7cd329bd749496f6c58b586a6c0dd0dc8201206f":["c7a8f6a0f831abdaf62496526336f43bbf7c5bbe"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"0837ab0472feecb3a54260729d845f839e1cbd72":["55eeb2534cd53d2a985669829df942468ebf5314"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a45bec74b98f6fc05f52770cfb425739e6563960"]},"commit2Childs":{"8f06b860886fc48ea071171354835b8aed8a94de":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"a45bec74b98f6fc05f52770cfb425739e6563960":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"c7a8f6a0f831abdaf62496526336f43bbf7c5bbe":["7cd329bd749496f6c58b586a6c0dd0dc8201206f"],"55eeb2534cd53d2a985669829df942468ebf5314":["0837ab0472feecb3a54260729d845f839e1cbd72"],"f45457a742a53533c348c4b990b1c579ff364467":["55eeb2534cd53d2a985669829df942468ebf5314"],"46bf1a48fd33bf34430ade646b7dd67b984be2a8":["8f06b860886fc48ea071171354835b8aed8a94de"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["c7a8f6a0f831abdaf62496526336f43bbf7c5bbe","d4d69c535930b5cce125cff868d40f6373dc27d4"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["46bf1a48fd33bf34430ade646b7dd67b984be2a8"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9d153abcf92dc5329d98571a8c3035df9bd80648","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"7cd329bd749496f6c58b586a6c0dd0dc8201206f":["f45457a742a53533c348c4b990b1c579ff364467"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"0837ab0472feecb3a54260729d845f839e1cbd72":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}