{"path":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"sandbox/contributions/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n          nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"1251\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n          nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"1251\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n          nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"1251\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"dd745d580729e528151b58aeda87ef82f1b95c9b":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dd745d580729e528151b58aeda87ef82f1b95c9b"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"dd745d580729e528151b58aeda87ef82f1b95c9b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}