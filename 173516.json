{"path":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","commits":[{"id":"b5d3613911d665344055ef7970e1783b3348b5c0","date":1521487734,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n    \n    final SolrDocument out = new SolrDocument();\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = out.get(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e7ba4f223712927a09f4dfb65a4c261d07ccc54","date":1544513757,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","pathOld":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","sourceNew":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n\n    final SolrDocument out = ResultContext.READASBYTES.get() == null ?\n        new SolrDocument() :\n        new BinaryResponseWriter.MaskCharSeqSolrDocument();\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = out.get(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","sourceOld":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n    \n    final SolrDocument out = new SolrDocument();\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = out.get(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3665b66adafb1514bba04cd1d5c477fcaa93d592","date":1576153597,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","pathOld":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","sourceNew":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n\n    BinaryResponseWriter.MaskCharSeqSolrDocument masked = null;\n    final SolrDocument out = ResultContext.READASBYTES.get() == null ?\n        new SolrDocument() :\n        (masked = new BinaryResponseWriter.MaskCharSeqSolrDocument());\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = masked == null ? out.get(fname) : masked.getRaw(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","sourceOld":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n\n    final SolrDocument out = ResultContext.READASBYTES.get() == null ?\n        new SolrDocument() :\n        new BinaryResponseWriter.MaskCharSeqSolrDocument();\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = out.get(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df724d84dab24a0cc54bec95a8680867adc7f171","date":1576156608,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","pathOld":"solr/core/src/java/org/apache/solr/response/DocsStreamer#convertLuceneDocToSolrDoc(Document,IndexSchema,ReturnFields).mjava","sourceNew":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n\n    BinaryResponseWriter.MaskCharSeqSolrDocument masked = null;\n    final SolrDocument out = ResultContext.READASBYTES.get() == null ?\n        new SolrDocument() :\n        (masked = new BinaryResponseWriter.MaskCharSeqSolrDocument());\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = masked == null ? out.get(fname) : masked.getRaw(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","sourceOld":"  /**\n   * Converts the specified <code>Document</code> into a <code>SolrDocument</code>.\n   * <p>\n   * The use of {@link ReturnFields} can be important even when it was already used to retrieve the \n   * {@link Document} from {@link SolrDocumentFetcher} because the Document may have been cached with \n   * more fields then are desired.\n   * </p>\n   * \n   * @param doc <code>Document</code> to be converted, must not be null\n   * @param schema <code>IndexSchema</code> containing the field/fieldType details for the index\n   *               the <code>Document</code> came from, must not be null.\n   * @param fields <code>ReturnFields</code> instance that can be use to limit the set of fields \n   *               that will be converted, must not be null\n   */\n  public static SolrDocument convertLuceneDocToSolrDoc(Document doc,\n                                                       final IndexSchema schema,\n                                                       final ReturnFields fields) {\n    // TODO move to SolrDocumentFetcher ?  Refactor to also call docFetcher.decorateDocValueFields(...) ?\n    assert null != doc;\n    assert null != schema;\n    assert null != fields;\n    \n    // can't just use fields.wantsField(String)\n    // because that doesn't include extra fields needed by transformers\n    final Set<String> fieldNamesNeeded = fields.getLuceneFieldNames();\n\n    final SolrDocument out = ResultContext.READASBYTES.get() == null ?\n        new SolrDocument() :\n        new BinaryResponseWriter.MaskCharSeqSolrDocument();\n\n    // NOTE: it would be tempting to try and optimize this to loop over fieldNamesNeeded\n    // when it's smaller then the IndexableField[] in the Document -- but that's actually *less* effecient\n    // since Document.getFields(String) does a full (internal) iteration over the full IndexableField[]\n    // see SOLR-11891\n    for (IndexableField f : doc.getFields()) {\n      final String fname = f.name();\n      if (null == fieldNamesNeeded || fieldNamesNeeded.contains(fname) ) {\n        // Make sure multivalued fields are represented as lists\n        Object existing = out.get(fname);\n        if (existing == null) {\n          SchemaField sf = schema.getFieldOrNull(fname);\n          if (sf != null && sf.multiValued()) {\n            List<Object> vals = new ArrayList<>();\n            vals.add(f);\n            out.setField(fname, vals);\n          } else {\n            out.setField(fname, f);\n          }\n        } else {\n          out.addField(fname, f);\n        }\n      }\n    }\n    return out;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"df724d84dab24a0cc54bec95a8680867adc7f171":["4e7ba4f223712927a09f4dfb65a4c261d07ccc54","3665b66adafb1514bba04cd1d5c477fcaa93d592"],"b5d3613911d665344055ef7970e1783b3348b5c0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4e7ba4f223712927a09f4dfb65a4c261d07ccc54":["b5d3613911d665344055ef7970e1783b3348b5c0"],"3665b66adafb1514bba04cd1d5c477fcaa93d592":["4e7ba4f223712927a09f4dfb65a4c261d07ccc54"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3665b66adafb1514bba04cd1d5c477fcaa93d592"]},"commit2Childs":{"df724d84dab24a0cc54bec95a8680867adc7f171":[],"b5d3613911d665344055ef7970e1783b3348b5c0":["4e7ba4f223712927a09f4dfb65a4c261d07ccc54"],"4e7ba4f223712927a09f4dfb65a4c261d07ccc54":["df724d84dab24a0cc54bec95a8680867adc7f171","3665b66adafb1514bba04cd1d5c477fcaa93d592"],"3665b66adafb1514bba04cd1d5c477fcaa93d592":["df724d84dab24a0cc54bec95a8680867adc7f171","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b5d3613911d665344055ef7970e1783b3348b5c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["df724d84dab24a0cc54bec95a8680867adc7f171","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}