{"path":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","commits":[{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        any |= applyDeletes(readerPool, info, coalescedDeletes, deletes);\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e175058b6aef7c3f9971e918edcc7ae7ef4347d1","date":1292497297,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n          if (infoStream != null) {\n            message(\"deletes touched \" + delCountInc + \" docIDs\");\n          }\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        any |= applyDeletes(readerPool, info, coalescedDeletes, deletes);\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a90f52202517a945eae4cb6148e6de4b5c2bc8b","date":1292520249,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n          if (infoStream != null) {\n            message(\"deletes touched \" + delCountInc + \" docIDs\");\n          }\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"/dev/null","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n\n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n\n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n\n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way\n    // when we're at or below the last of the\n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n\n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n\n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n\n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b64b8b892fe20789d3b47dfa0a68306d76525b8b","date":1295457709,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            assert numTerms.get() >= 0;\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n            assert bytesUsed.get() >= 0;\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n\n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n\n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n\n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way\n    // when we're at or below the last of the\n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n\n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n\n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            assert numTerms.get() >= 0;\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n            assert bytesUsed.get() >= 0;\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n\n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n\n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n\n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n\n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way\n    // when we're at or below the last of the\n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n\n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n\n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n\n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":null,"sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            assert numTerms.get() >= 0;\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n            assert bytesUsed.get() >= 0;\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":null,"sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n    \n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n    \n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n    \n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way \n    // when we're at or below the last of the \n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n      \n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n      \n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n    \n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/BufferedDeletes#applyDeletes(IndexWriter.ReaderPool,SegmentInfos,SegmentInfos).mjava","sourceNew":null,"sourceOld":"  public synchronized boolean applyDeletes(IndexWriter.ReaderPool readerPool, SegmentInfos segmentInfos, SegmentInfos applyInfos) throws IOException {\n    if (!any()) {\n      return false;\n    }\n    final long t0 = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"applyDeletes: applyInfos=\" + applyInfos + \"; index=\" + segmentInfos);\n    }\n\n    assert checkDeleteStats();\n\n    assert applyInfos.size() > 0;\n\n    boolean any = false;\n\n    final SegmentInfo lastApplyInfo = applyInfos.lastElement();\n    final int lastIdx = segmentInfos.indexOf(lastApplyInfo);\n\n    final SegmentInfo firstInfo = applyInfos.firstElement();\n    final int firstIdx = segmentInfos.indexOf(firstInfo);\n\n    // applyInfos must be a slice of segmentInfos\n    assert lastIdx - firstIdx + 1 == applyInfos.size();\n\n    // iterate over all segment infos backwards\n    // coalesceing deletes along the way\n    // when we're at or below the last of the\n    // segments to apply to, start applying the deletes\n    // we traverse up to the first apply infos\n    SegmentDeletes coalescedDeletes = null;\n    boolean hasDeletes = false;\n    for (int segIdx=segmentInfos.size()-1; segIdx >= firstIdx; segIdx--) {\n      final SegmentInfo info = segmentInfos.info(segIdx);\n      final SegmentDeletes deletes = deletesMap.get(info);\n      assert deletes == null || deletes.any();\n\n      if (deletes == null && coalescedDeletes == null) {\n        continue;\n      }\n\n      if (infoStream != null) {\n        message(\"applyDeletes: seg=\" + info + \" segment's deletes=[\" + (deletes == null ? \"null\" : deletes) + \"]; coalesced deletes=[\" + (coalescedDeletes == null ? \"null\" : coalescedDeletes) + \"]\");\n      }\n\n      hasDeletes |= deletes != null;\n\n      if (segIdx <= lastIdx && hasDeletes) {\n\n        final long delCountInc = applyDeletes(readerPool, info, coalescedDeletes, deletes);\n\n        if (delCountInc != 0) {\n          any = true;\n        }\n        if (infoStream != null) {\n          message(\"deletes touched \" + delCountInc + \" docIDs\");\n        }\n\n        if (deletes != null) {\n          // we've applied doc ids, and they're only applied\n          // on the current segment\n          bytesUsed.addAndGet(-deletes.docIDs.size() * SegmentDeletes.BYTES_PER_DEL_DOCID);\n          deletes.clearDocIDs();\n        }\n      }\n\n      // now coalesce at the max limit\n      if (deletes != null) {\n        if (coalescedDeletes == null) {\n          coalescedDeletes = new SegmentDeletes();\n        }\n        // TODO: we could make this single pass (coalesce as\n        // we apply the deletes\n        coalescedDeletes.update(deletes, true);\n      }\n    }\n\n    // move all deletes to segment just before our merge.\n    if (firstIdx > 0) {\n\n      SegmentDeletes mergedDeletes = null;\n      // TODO: we could also make this single pass\n      for (SegmentInfo info : applyInfos) {\n        final SegmentDeletes deletes = deletesMap.get(info);\n        if (deletes != null) {\n          assert deletes.any();\n          if (mergedDeletes == null) {\n            mergedDeletes = getDeletes(segmentInfos.info(firstIdx-1));\n            numTerms.addAndGet(-mergedDeletes.numTermDeletes.get());\n            assert numTerms.get() >= 0;\n            bytesUsed.addAndGet(-mergedDeletes.bytesUsed.get());\n            assert bytesUsed.get() >= 0;\n          }\n\n          mergedDeletes.update(deletes, true);\n        }\n      }\n\n      if (mergedDeletes != null) {\n        numTerms.addAndGet(mergedDeletes.numTermDeletes.get());\n        bytesUsed.addAndGet(mergedDeletes.bytesUsed.get());\n      }\n\n      if (infoStream != null) {\n        if (mergedDeletes != null) {\n          message(\"applyDeletes: merge all deletes into seg=\" + segmentInfos.info(firstIdx-1) + \": \" + mergedDeletes);\n        } else {\n          message(\"applyDeletes: no deletes to merge\");\n        }\n      }\n    } else {\n      // We drop the deletes in this case, because we've\n      // applied them to segment infos starting w/ the first\n      // segment.  There are no prior segments so there's no\n      // reason to keep them around.  When the applyInfos ==\n      // segmentInfos this means all deletes have been\n      // removed:\n    }\n    remove(applyInfos);\n\n    assert checkDeleteStats();\n    assert applyInfos != segmentInfos || !any();\n\n    if (infoStream != null) {\n      message(\"applyDeletes took \" + (System.currentTimeMillis()-t0) + \" msec\");\n    }\n    return any;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b64b8b892fe20789d3b47dfa0a68306d76525b8b":["5a90f52202517a945eae4cb6148e6de4b5c2bc8b"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5a90f52202517a945eae4cb6148e6de4b5c2bc8b"],"e175058b6aef7c3f9971e918edcc7ae7ef4347d1":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5a90f52202517a945eae4cb6148e6de4b5c2bc8b"],"5a90f52202517a945eae4cb6148e6de4b5c2bc8b":["e175058b6aef7c3f9971e918edcc7ae7ef4347d1"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b64b8b892fe20789d3b47dfa0a68306d76525b8b"],"c19f985e36a65cc969e8e564fe337a0d41512075":["b64b8b892fe20789d3b47dfa0a68306d76525b8b"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["e79a6d080bdd5b2a8f56342cf571b5476de04180","c19f985e36a65cc969e8e564fe337a0d41512075"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c19f985e36a65cc969e8e564fe337a0d41512075"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["e175058b6aef7c3f9971e918edcc7ae7ef4347d1"],"b64b8b892fe20789d3b47dfa0a68306d76525b8b":["e79a6d080bdd5b2a8f56342cf571b5476de04180","c19f985e36a65cc969e8e564fe337a0d41512075"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","ab5cb6a74aefb78aa0569857970b9151dfe2e787","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"e175058b6aef7c3f9971e918edcc7ae7ef4347d1":["5a90f52202517a945eae4cb6148e6de4b5c2bc8b"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"5a90f52202517a945eae4cb6148e6de4b5c2bc8b":["b64b8b892fe20789d3b47dfa0a68306d76525b8b","ab5cb6a74aefb78aa0569857970b9151dfe2e787","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c19f985e36a65cc969e8e564fe337a0d41512075":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}