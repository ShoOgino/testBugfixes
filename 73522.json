{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","commits":[{"id":"475693cad374d888e9513c658c7457962de0e3fa","date":1451987067,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"/dev/null","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_5_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_5_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6392c263ac1e0e2a22a7f2d50f499e76971801d","date":1456927541,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_6_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_6_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_5_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_5_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_6_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_6_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_5_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_5_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85b9829d27224bda451a373a47f081afb1c664b8","date":1498846708,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_7_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_7_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_6_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_6_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc018b79379c67835b40b1259cd3dc931df60944","date":1499109112,"type":3,"author":"Anshum Gupta","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_7_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_7_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_6_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_6_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30c8e5574b55d57947e989443dfde611646530ee","date":1499131153,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_7_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_7_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_6_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_6_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d722b735bc69d2234e957cb69cf96ad28ea7e1c3","date":1546867201,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_8_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_8_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_7_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_7_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2","date":1591961131,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/custom/TestCustomAnalyzer#testFactoryHtmlStripClassicFolding().mjava","sourceNew":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(LUCENE_8_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(LUCENE_8_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","sourceOld":"  public void testFactoryHtmlStripClassicFolding() throws Exception {\n    CustomAnalyzer a = CustomAnalyzer.builder()\n        .withDefaultMatchVersion(Version.LUCENE_8_0_0)\n        .addCharFilter(HTMLStripCharFilterFactory.class)\n        .withTokenizer(ClassicTokenizerFactory.class)\n        .addTokenFilter(ASCIIFoldingFilterFactory.class, \"preserveOriginal\", \"true\")\n        .addTokenFilter(LowerCaseFilterFactory.class)\n        .withPositionIncrementGap(100)\n        .withOffsetGap(1000)\n        .build();\n    \n    assertSame(ClassicTokenizerFactory.class, a.getTokenizerFactory().getClass());\n    List<CharFilterFactory> charFilters = a.getCharFilterFactories();\n    assertEquals(1, charFilters.size());\n    assertEquals(HTMLStripCharFilterFactory.class, charFilters.get(0).getClass());\n    List<TokenFilterFactory> tokenFilters = a.getTokenFilterFactories();\n    assertEquals(2, tokenFilters.size());\n    assertSame(ASCIIFoldingFilterFactory.class, tokenFilters.get(0).getClass());\n    assertSame(LowerCaseFilterFactory.class, tokenFilters.get(1).getClass());\n    assertEquals(100, a.getPositionIncrementGap(\"dummy\"));\n    assertEquals(1000, a.getOffsetGap(\"dummy\"));\n    assertSame(Version.LUCENE_8_0_0, a.getVersion());\n\n    assertAnalyzesTo(a, \"<p>foo bar</p> FOO BAR\", \n        new String[] { \"foo\", \"bar\", \"foo\", \"bar\" },\n        new int[]    { 1,     1,     1,     1});\n    assertAnalyzesTo(a, \"<p><b>föó</b> bär     FÖÖ BAR</p>\", \n        new String[] { \"foo\", \"föó\", \"bar\", \"bär\", \"foo\", \"föö\", \"bar\" },\n        new int[]    { 1,     0,     1,     0,     1,     0,     1});\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"475693cad374d888e9513c658c7457962de0e3fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d6392c263ac1e0e2a22a7f2d50f499e76971801d":["475693cad374d888e9513c658c7457962de0e3fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc018b79379c67835b40b1259cd3dc931df60944":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273","85b9829d27224bda451a373a47f081afb1c664b8"],"30c8e5574b55d57947e989443dfde611646530ee":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273","cc018b79379c67835b40b1259cd3dc931df60944"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["d722b735bc69d2234e957cb69cf96ad28ea7e1c3"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["475693cad374d888e9513c658c7457962de0e3fa","d6392c263ac1e0e2a22a7f2d50f499e76971801d"],"85b9829d27224bda451a373a47f081afb1c664b8":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"],"d722b735bc69d2234e957cb69cf96ad28ea7e1c3":["cc018b79379c67835b40b1259cd3dc931df60944"]},"commit2Childs":{"475693cad374d888e9513c658c7457962de0e3fa":["d6392c263ac1e0e2a22a7f2d50f499e76971801d","cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"d6392c263ac1e0e2a22a7f2d50f499e76971801d":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["475693cad374d888e9513c658c7457962de0e3fa"],"cc018b79379c67835b40b1259cd3dc931df60944":["30c8e5574b55d57947e989443dfde611646530ee","d722b735bc69d2234e957cb69cf96ad28ea7e1c3"],"30c8e5574b55d57947e989443dfde611646530ee":[],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["cc018b79379c67835b40b1259cd3dc931df60944","30c8e5574b55d57947e989443dfde611646530ee","85b9829d27224bda451a373a47f081afb1c664b8"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85b9829d27224bda451a373a47f081afb1c664b8":["cc018b79379c67835b40b1259cd3dc931df60944"],"d722b735bc69d2234e957cb69cf96ad28ea7e1c3":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["30c8e5574b55d57947e989443dfde611646530ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}