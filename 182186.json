{"path":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"/dev/null","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)loader.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":null,"sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      return (Analyzer)loader.newInstance(analyzerName);\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          plugin.init( DOMUtil.toMapExcept(node.getAttributes(),\"class\") );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"/dev/null","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"88f4b27679f86131b71575c0c68cae9ff261ac35","date":1304365100,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":["4880f7e65af3c0bb359e5507a036acd44614bdcf","bf0e17cfd70114fa265a0ac990861cc37685024e","8b712a9305796bf68e7e2515c4937771deeb5351"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      // No need to be core-aware as Analyzers are not in the core-aware list\n      final Class<? extends Analyzer> clazz = loader.findClass(analyzerName).asSubclass(Analyzer.class);\n      try {\n        try {\n          // first try to use a ctor with version parameter (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Configuration Error: Analyzer '\" + clazz.getName() +\n              \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"Cannot load analyzer: \"+analyzerName );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","pathOld":"solr/src/java/org/apache/solr/schema/IndexSchema#readAnalyzer(Node).mjava","sourceNew":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","sourceOld":"  //\n  // <analyzer><tokenizer class=\"....\"/><tokenizer class=\"....\" arg=\"....\">\n  //\n  //\n  private Analyzer readAnalyzer(Node node) throws XPathExpressionException {\n    // parent node used to be passed in as \"fieldtype\"\n    // if (!fieldtype.hasChildNodes()) return null;\n    // Node node = DOMUtil.getChild(fieldtype,\"analyzer\");\n\n    if (node == null) return null;\n    NamedNodeMap attrs = node.getAttributes();\n    String analyzerName = DOMUtil.getAttr(attrs,\"class\");\n    if (analyzerName != null) {\n      try {\n        // No need to be core-aware as Analyzers are not in the core-aware list\n        final Class<? extends Analyzer> clazz = loader.findClass\n          (analyzerName).asSubclass(Analyzer.class);\n\n        try {\n          // first try to use a ctor with version parameter \n          // (needed for many new Analyzers that have no default one anymore)\n          Constructor<? extends Analyzer> cnstr = clazz.getConstructor(Version.class);\n          final String matchVersionStr = DOMUtil.getAttr(attrs, LUCENE_MATCH_VERSION_PARAM);\n          final Version luceneMatchVersion = (matchVersionStr == null) ?\n            solrConfig.luceneMatchVersion : Config.parseLuceneVersionString(matchVersionStr);\n          if (luceneMatchVersion == null) {\n            throw new SolrException\n              ( SolrException.ErrorCode.SERVER_ERROR,\n                \"Configuration Error: Analyzer '\" + clazz.getName() +\n                \"' needs a 'luceneMatchVersion' parameter\");\n          }\n          return cnstr.newInstance(luceneMatchVersion);\n        } catch (NoSuchMethodException nsme) {\n          // otherwise use default ctor\n          return clazz.newInstance();\n        }\n      } catch (Exception e) {\n        log.error(\"Cannot load analyzer: \"+analyzerName, e);\n        throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n                                 \"Cannot load analyzer: \"+analyzerName, e );\n      }\n    }\n\n    XPath xpath = XPathFactory.newInstance().newXPath();\n\n    // Load the CharFilters\n    // --------------------------------------------------------------------------------\n    final ArrayList<CharFilterFactory> charFilters = new ArrayList<CharFilterFactory>();\n    AbstractPluginLoader<CharFilterFactory> charFilterLoader =\n      new AbstractPluginLoader<CharFilterFactory>( \"[schema.xml] analyzer/charFilter\", false, false )\n    {\n      @Override\n      protected void init(CharFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          charFilters.add( plugin );\n        }\n      }\n\n      @Override\n      protected CharFilterFactory register(String name, CharFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    charFilterLoader.load( solrConfig.getResourceLoader(), (NodeList)xpath.evaluate(\"./charFilter\", node, XPathConstants.NODESET) );\n\n    // Load the Tokenizer\n    // Although an analyzer only allows a single Tokenizer, we load a list to make sure\n    // the configuration is ok\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenizerFactory> tokenizers = new ArrayList<TokenizerFactory>(1);\n    AbstractPluginLoader<TokenizerFactory> tokenizerLoader =\n      new AbstractPluginLoader<TokenizerFactory>( \"[schema.xml] analyzer/tokenizer\", false, false )\n    {\n      @Override\n      protected void init(TokenizerFactory plugin, Node node) throws Exception {\n        if( !tokenizers.isEmpty() ) {\n          throw new SolrException( SolrException.ErrorCode.SERVER_ERROR,\n              \"The schema defines multiple tokenizers for: \"+node );\n        }\n        final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n        // copy the luceneMatchVersion from config, if not set\n        if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n          params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n        plugin.init( params );\n        tokenizers.add( plugin );\n      }\n\n      @Override\n      protected TokenizerFactory register(String name, TokenizerFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    tokenizerLoader.load( loader, (NodeList)xpath.evaluate(\"./tokenizer\", node, XPathConstants.NODESET) );\n    \n    // Make sure something was loaded\n    if( tokenizers.isEmpty() ) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\"analyzer without class or tokenizer & filter list\");\n    }\n    \n\n    // Load the Filters\n    // --------------------------------------------------------------------------------\n    final ArrayList<TokenFilterFactory> filters = new ArrayList<TokenFilterFactory>();\n    AbstractPluginLoader<TokenFilterFactory> filterLoader = \n      new AbstractPluginLoader<TokenFilterFactory>( \"[schema.xml] analyzer/filter\", false, false )\n    {\n      @Override\n      protected void init(TokenFilterFactory plugin, Node node) throws Exception {\n        if( plugin != null ) {\n          final Map<String,String> params = DOMUtil.toMapExcept(node.getAttributes(),\"class\");\n          // copy the luceneMatchVersion from config, if not set\n          if (!params.containsKey(LUCENE_MATCH_VERSION_PARAM))\n            params.put(LUCENE_MATCH_VERSION_PARAM, solrConfig.luceneMatchVersion.toString());\n          plugin.init( params );\n          filters.add( plugin );\n        }\n      }\n\n      @Override\n      protected TokenFilterFactory register(String name, TokenFilterFactory plugin) throws Exception {\n        return null; // used for map registration\n      }\n    };\n    filterLoader.load( loader, (NodeList)xpath.evaluate(\"./filter\", node, XPathConstants.NODESET) );\n\n    return new TokenizerChain(charFilters.toArray(new CharFilterFactory[charFilters.size()]),\n        tokenizers.get(0), filters.toArray(new TokenFilterFactory[filters.size()]));\n  }\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["88f4b27679f86131b71575c0c68cae9ff261ac35","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a3776dccca01c11e7046323cfad46a3b4a471233"],"a3776dccca01c11e7046323cfad46a3b4a471233":["1da8d55113b689b06716246649de6f62430f15c0","88f4b27679f86131b71575c0c68cae9ff261ac35"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["1da8d55113b689b06716246649de6f62430f15c0","88f4b27679f86131b71575c0c68cae9ff261ac35"],"88f4b27679f86131b71575c0c68cae9ff261ac35":["1da8d55113b689b06716246649de6f62430f15c0"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["88f4b27679f86131b71575c0c68cae9ff261ac35"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"1da8d55113b689b06716246649de6f62430f15c0":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","88f4b27679f86131b71575c0c68cae9ff261ac35"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"88f4b27679f86131b71575c0c68cae9ff261ac35":["c26f00b574427b55127e869b935845554afde1fa","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}