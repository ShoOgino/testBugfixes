{"path":"modules/spatial/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"935445a30e9e8dc0240a7c78efc73d08c2faa6a8","date":1329778521,"type":1,"author":"David Wayne Smiley","isMerge":false,"pathNew":"modules/spatial/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"modules/spatial/src/main/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33ee89d976c91275e5be5da438ca0977b1c5b90f","date":1329808149,"type":5,"author":"Ryan McKinley","isMerge":false,"pathNew":"modules/spatial-TEMP/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"modules/spatial/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a24bff9b8b5990b2e39206b8742b848c8d88181","date":1330491455,"type":1,"author":"Ryan McKinley","isMerge":false,"pathNew":"modules/spatial/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"modules/spatial/strategy/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de3ae51f6d7d658f4c6d1cc9b74cc4b5e45f294e","date":1330665960,"type":5,"author":"David Wayne Smiley","isMerge":false,"pathNew":"modules/spatial/src/java/org/apache/lucene/spatial/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"modules/spatial/src/java/org/apache/lucene/spatial/strategy/prefix/RecursivePrefixTreeFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext ctx, Bits acceptDocs) throws IOException {\n    AtomicReader reader = ctx.reader();\n    OpenBitSet bits = new OpenBitSet(reader.maxDoc());\n    Terms terms = reader.terms(fieldName);\n    if (terms == null)\n      return null;\n    TermsEnum termsEnum = terms.iterator(null);\n    DocsEnum docsEnum = null;//cached for termsEnum.docs() calls\n    Node scanCell = null;\n\n    //cells is treated like a stack. LinkedList conveniently has bulk add to beginning. It's in sorted order so that we\n    //  always advance forward through the termsEnum index.\n    LinkedList<Node> cells = new LinkedList<Node>(\n        grid.getWorldNode().getSubCells(queryShape) );\n\n    //This is a recursive algorithm that starts with one or more \"big\" cells, and then recursively dives down into the\n    // first such cell that intersects with the query shape.  It's a depth first traversal because we don't move onto\n    // the next big cell (breadth) until we're completely done considering all smaller cells beneath it. For a given\n    // cell, if it's *within* the query shape then we can conveniently short-circuit the depth traversal and\n    // grab all documents assigned to this cell/term.  For an intersection of the cell and query shape, we either\n    // recursively step down another grid level or we decide heuristically (via prefixGridScanLevel) that there aren't\n    // that many points, and so we scan through all terms within this cell (i.e. the term starts with the cell's term),\n    // seeing which ones are within the query shape.\n    while(!cells.isEmpty()) {\n      final Node cell = cells.removeFirst();\n      final BytesRef cellTerm = new BytesRef(cell.getTokenBytes());\n      TermsEnum.SeekStatus seekStat = termsEnum.seekCeil(cellTerm);\n      if (seekStat == TermsEnum.SeekStatus.END)\n        break;\n      if (seekStat == TermsEnum.SeekStatus.NOT_FOUND)\n        continue;\n      if (cell.getLevel() == detailLevel || cell.isLeaf()) {\n        docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n        addDocs(docsEnum,bits);\n      } else {//any other intersection\n        //If the next indexed term is the leaf marker, then add all of them\n        BytesRef nextCellTerm = termsEnum.next();\n        assert StringHelper.startsWith(nextCellTerm, cellTerm);\n        scanCell = grid.getNode(nextCellTerm.bytes, nextCellTerm.offset, nextCellTerm.length, scanCell);\n        if (scanCell.isLeaf()) {\n          docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n          addDocs(docsEnum,bits);\n          termsEnum.next();//move pointer to avoid potential redundant addDocs() below\n        }\n\n        //Decide whether to continue to divide & conquer, or whether it's time to scan through terms beneath this cell.\n        // Scanning is a performance optimization trade-off.\n        boolean scan = cell.getLevel() >= prefixGridScanLevel;//simple heuristic\n\n        if (!scan) {\n          //Divide & conquer\n          cells.addAll(0, cell.getSubCells(queryShape));//add to beginning\n        } else {\n          //Scan through all terms within this cell to see if they are within the queryShape. No seek()s.\n          for(BytesRef term = termsEnum.term(); term != null && StringHelper.startsWith(term,cellTerm); term = termsEnum.next()) {\n            scanCell = grid.getNode(term.bytes, term.offset, term.length, scanCell);\n            int termLevel = scanCell.getLevel();\n            if (termLevel > detailLevel)\n              continue;\n            if (termLevel == detailLevel || scanCell.isLeaf()) {\n              //TODO should put more thought into implications of box vs point\n              Shape cShape = termLevel == grid.getMaxLevels() ? scanCell.getCenter() : scanCell.getShape();\n              if(queryShape.relate(cShape, grid.getSpatialContext()) == SpatialRelation.DISJOINT)\n                continue;\n\n              docsEnum = termsEnum.docs(acceptDocs, docsEnum, false);\n              addDocs(docsEnum,bits);\n            }\n          }//term loop\n        }\n      }\n    }//cell loop\n\n    return bits;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"6a24bff9b8b5990b2e39206b8742b848c8d88181":["33ee89d976c91275e5be5da438ca0977b1c5b90f"],"935445a30e9e8dc0240a7c78efc73d08c2faa6a8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"33ee89d976c91275e5be5da438ca0977b1c5b90f":["935445a30e9e8dc0240a7c78efc73d08c2faa6a8"],"de3ae51f6d7d658f4c6d1cc9b74cc4b5e45f294e":["6a24bff9b8b5990b2e39206b8742b848c8d88181"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"6a24bff9b8b5990b2e39206b8742b848c8d88181":["de3ae51f6d7d658f4c6d1cc9b74cc4b5e45f294e"],"935445a30e9e8dc0240a7c78efc73d08c2faa6a8":["33ee89d976c91275e5be5da438ca0977b1c5b90f"],"33ee89d976c91275e5be5da438ca0977b1c5b90f":["6a24bff9b8b5990b2e39206b8742b848c8d88181"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["935445a30e9e8dc0240a7c78efc73d08c2faa6a8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"de3ae51f6d7d658f4c6d1cc9b74cc4b5e45f294e":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["de3ae51f6d7d658f4c6d1cc9b74cc4b5e45f294e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}