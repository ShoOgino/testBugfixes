{"path":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","commits":[{"id":"714aa8d007eef87d7203cfc6e0fe4dab8dd8a497","date":1417181893,"type":1,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#initTokensArray().mjava","sourceNew":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need. We use some estimation factors taken from Wikipedia\n    //  that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat\n      int size = (int) vector.size();\n      if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way\n        size = 128;\n      }\n      sumTotalTermFreq = (int)(size * 2.4);\n    }\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n    return new TokenLL[originalPositionEstimate];\n  }\n\n","sourceOld":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need. We use some estimation factors taken from Wikipedia\n    //  that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat\n      int size = (int) vector.size();\n      if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way\n        size = 128;\n      }\n      sumTotalTermFreq = (int)(size * 2.4);\n    }\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n    return new TokenLL[originalPositionEstimate];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd5cb61545fbf8394e449204e9780415b9f4c6fc","date":1429738516,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","sourceNew":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need from term stats.  We use some estimation factors taken from\n    //  Wikipedia that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat\n      int size = (int) vector.size();\n      if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way\n        size = 128;\n      }\n      sumTotalTermFreq = (int)(size * 2.4);\n    }\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n\n    // This estimate is based on maxStartOffset. Err on the side of this being larger than needed.\n    final int offsetLimitPositionEstimate = (int) (maxStartOffset / 5.0);\n\n    // Take the smaller of the two estimates, but no smaller than 64\n    return new TokenLL[Math.max(64, Math.min(originalPositionEstimate, offsetLimitPositionEstimate))];\n  }\n\n","sourceOld":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need. We use some estimation factors taken from Wikipedia\n    //  that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat\n      int size = (int) vector.size();\n      if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way\n        size = 128;\n      }\n      sumTotalTermFreq = (int)(size * 2.4);\n    }\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n    return new TokenLL[originalPositionEstimate];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"086ffe31d8fba0110227db122974163709ecc1b4","date":1509678141,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","sourceNew":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need from term stats.  We use some estimation factors taken from\n    //  Wikipedia that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    assert sumTotalTermFreq != -1;\n\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n\n    // This estimate is based on maxStartOffset. Err on the side of this being larger than needed.\n    final int offsetLimitPositionEstimate = (int) (maxStartOffset / 5.0);\n\n    // Take the smaller of the two estimates, but no smaller than 64\n    return new TokenLL[Math.max(64, Math.min(originalPositionEstimate, offsetLimitPositionEstimate))];\n  }\n\n","sourceOld":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need from term stats.  We use some estimation factors taken from\n    //  Wikipedia that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat\n      int size = (int) vector.size();\n      if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way\n        size = 128;\n      }\n      sumTotalTermFreq = (int)(size * 2.4);\n    }\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n\n    // This estimate is based on maxStartOffset. Err on the side of this being larger than needed.\n    final int offsetLimitPositionEstimate = (int) (maxStartOffset / 5.0);\n\n    // Take the smaller of the two estimates, but no smaller than 64\n    return new TokenLL[Math.max(64, Math.min(originalPositionEstimate, offsetLimitPositionEstimate))];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermVector#initTokensArray().mjava","sourceNew":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need from term stats.  We use some estimation factors taken from\n    //  Wikipedia that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    assert sumTotalTermFreq != -1;\n\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n\n    // This estimate is based on maxStartOffset. Err on the side of this being larger than needed.\n    final int offsetLimitPositionEstimate = (int) (maxStartOffset / 5.0);\n\n    // Take the smaller of the two estimates, but no smaller than 64\n    return new TokenLL[Math.max(64, Math.min(originalPositionEstimate, offsetLimitPositionEstimate))];\n  }\n\n","sourceOld":"  private TokenLL[] initTokensArray() throws IOException {\n    // Estimate the number of position slots we need from term stats.  We use some estimation factors taken from\n    //  Wikipedia that reduce the likelihood of needing to expand the array.\n    int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();\n    if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat\n      int size = (int) vector.size();\n      if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way\n        size = 128;\n      }\n      sumTotalTermFreq = (int)(size * 2.4);\n    }\n    final int originalPositionEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this\n\n    // This estimate is based on maxStartOffset. Err on the side of this being larger than needed.\n    final int offsetLimitPositionEstimate = (int) (maxStartOffset / 5.0);\n\n    // Take the smaller of the two estimates, but no smaller than 64\n    return new TokenLL[Math.max(64, Math.min(originalPositionEstimate, offsetLimitPositionEstimate))];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"714aa8d007eef87d7203cfc6e0fe4dab8dd8a497":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"086ffe31d8fba0110227db122974163709ecc1b4":["dd5cb61545fbf8394e449204e9780415b9f4c6fc"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["dd5cb61545fbf8394e449204e9780415b9f4c6fc","086ffe31d8fba0110227db122974163709ecc1b4"],"dd5cb61545fbf8394e449204e9780415b9f4c6fc":["714aa8d007eef87d7203cfc6e0fe4dab8dd8a497"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"]},"commit2Childs":{"714aa8d007eef87d7203cfc6e0fe4dab8dd8a497":["dd5cb61545fbf8394e449204e9780415b9f4c6fc"],"086ffe31d8fba0110227db122974163709ecc1b4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["714aa8d007eef87d7203cfc6e0fe4dab8dd8a497"],"dd5cb61545fbf8394e449204e9780415b9f4c6fc":["086ffe31d8fba0110227db122974163709ecc1b4","d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}