{"path":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","commits":[{"id":"eda61b1e90b490cc5837200e04c02639a0d272c7","date":1358795519,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"/dev/null","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReader(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"/dev/null","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReader(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37b84753dc1f66eba4973779932885fe42cde001","date":1358812051,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReader(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReader(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":["eda61b1e90b490cc5837200e04c02639a0d272c7"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"818c86419d333447415a4e14fec4365320992e26","date":1370973407,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      vectorsStream = d.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream = null;\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6120217e09092280e618050d052131ebcf6802d5","date":1395430033,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      int version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      if (indexStream.getFilePointer() != indexStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + indexStreamFN + \"\\\": read \" + indexStream.getFilePointer() + \" vs size \" + indexStream.length() + \" (resource: \" + indexStream + \")\");\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      int version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      if (indexStream.getFilePointer() != indexStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + indexStreamFN + \"\\\": read \" + indexStream.getFilePointer() + \" vs size \" + indexStream.length() + \" (resource: \" + indexStream + \")\");\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    IndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      int version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      if (indexStream.getFilePointer() != indexStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + indexStreamFN + \"\\\": read \" + indexStream.getFilePointer() + \" vs size \" + indexStream.length() + \" (resource: \" + indexStream + \")\");\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a88f37cd0154833b5c58daac509eb8be347d0f2","date":1397029487,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b612f3f700a1ca999f12198b7a33c65b4a96fd0","date":1406127397,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(vectorsStream);\n        vectorsStream.seek(pos);\n      }\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(vectorsStream);\n        vectorsStream.seek(pos);\n      }\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(vectorsStream);\n        vectorsStream.seek(pos);\n      }\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":["6120217e09092280e618050d052131ebcf6802d5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"389e8bca54f58e35576077f3ff46f123b3660018","date":1411859915,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n      assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      indexStream.readVLong(); // the end of the data file\n      CodecUtil.checkFooter(indexStream);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(vectorsStream);\n        vectorsStream.seek(pos);\n      }\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ac4bff3307e88928bf48cd1a283ff7da1f82464","date":1411914960,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n        assert CodecUtil.segmentHeaderLength(codecNameIdx) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkSegmentHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n      assert CodecUtil.segmentHeaderLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      indexStream.readVLong(); // the end of the data file\n      CodecUtil.checkFooter(indexStream);\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["b88448324d3a96c5842455dabea63450b697b58f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a78b813d9350cc28625598f6dbbb49b586a40618","date":1412073147,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId());\n        assert CodecUtil.segmentHeaderLength(codecNameIdx) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId());\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    ChecksumIndexInput indexStream = null;\n    try {\n      // Load the index into memory\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n      indexStream = d.openChecksumInput(indexStreamFN, context);\n      final String codecNameIdx = formatName + CODEC_SFX_IDX;\n      version = CodecUtil.checkHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT);\n      assert CodecUtil.headerLength(codecNameIdx) == indexStream.getFilePointer();\n      indexReader = new CompressingStoredFieldsIndexReader(indexStream, si);\n      \n      if (version >= VERSION_CHECKSUM) {\n        indexStream.readVLong(); // the end of the data file\n        CodecUtil.checkFooter(indexStream);\n      } else {\n        CodecUtil.checkEOF(indexStream);\n      }\n      indexStream.close();\n      indexStream = null;\n\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.headerLength(codecNameDat) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      if (version >= VERSION_CHECKSUM) {\n        // NOTE: data file is too costly to verify checksum against all the bytes on open,\n        // but for now we at least verify proper structure of the checksum footer: which looks\n        // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n        // such as file truncation.\n        CodecUtil.retrieveChecksum(vectorsStream);\n        vectorsStream.seek(pos);\n      }\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, indexStream);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkSegmentHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.segmentHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkSegmentHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.segmentHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59d4661023aa9541b0a759e4d2e11dcf83b923a0","date":1420124226,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b88448324d3a96c5842455dabea63450b697b58f","date":1421779050,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        input.readVLong(); // the end of the data file\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":["6ac4bff3307e88928bf48cd1a283ff7da1f82464"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.getDocCount();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5","date":1488285484,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n\n      vectorsStream.seek(maxPointer);\n      numChunks = vectorsStream.readVLong();\n      numDirtyChunks = vectorsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n      \n      if (version >= VERSION_CHUNK_STATS) {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n        if (numDirtyChunks > numChunks) {\n          throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n        }\n      } else {\n        numChunks = numDirtyChunks = -1;\n      }\n      \n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70a4487b07c49a1861c05720e04624826ecbe9fa","date":1580924108,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(vectorsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      FieldsIndex indexReader = null;\n      long maxPointer = -1;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"tvx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong(); // the end of the data section\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, VECTORS_INDEX_EXTENSION_PREFIX, VECTORS_INDEX_CODEC_NAME, si.getId());\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.indexReader = indexReader;\n      this.maxPointer = maxPointer;\n\n      long pos = vectorsStream.getFilePointer();\n      vectorsStream.seek(maxPointer);\n      numChunks = vectorsStream.readVLong();\n      numDirtyChunks = vectorsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n    int version = -1;\n    CompressingStoredFieldsIndexReader indexReader = null;\n    \n    long maxPointer = -1;\n    \n    // Load the index into memory\n    final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_INDEX_EXTENSION);\n    try (ChecksumIndexInput input = d.openChecksumInput(indexName, context)) {\n      Throwable priorE = null;\n      try {\n        final String codecNameIdx = formatName + CODEC_SFX_IDX;\n        version = CodecUtil.checkIndexHeader(input, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n        assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == input.getFilePointer();\n        indexReader = new CompressingStoredFieldsIndexReader(input, si);\n        maxPointer = input.readVLong(); // the end of the data section\n      } catch (Throwable exception) {\n        priorE = exception;\n      } finally {\n        CodecUtil.checkFooter(input, priorE);\n      }\n    }\n    \n    this.version = version;\n    this.indexReader = indexReader;\n    this.maxPointer = maxPointer;\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      final String codecNameDat = formatName + CODEC_SFX_DAT;\n      int version2 = CodecUtil.checkIndexHeader(vectorsStream, codecNameDat, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      if (version != version2) {\n        throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, vectorsStream);\n      }\n      assert CodecUtil.indexHeaderLength(codecNameDat, segmentSuffix) == vectorsStream.getFilePointer();\n      \n      long pos = vectorsStream.getFilePointer();\n\n      vectorsStream.seek(maxPointer);\n      numChunks = vectorsStream.readVLong();\n      numDirtyChunks = vectorsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b78d8dfe50af510bace3600bfc4cfa0b031f776","date":1598430423,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    ChecksumIndexInput metaIn = null;\n    try {\n      // Open the data file\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(vectorsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      if (version >= VERSION_OFFHEAP_INDEX) {\n        final String metaStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION);\n        metaIn = d.openChecksumInput(metaStreamFN, IOContext.READONCE);\n        CodecUtil.checkIndexHeader(metaIn, VECTORS_INDEX_CODEC_NAME + \"Meta\", META_VERSION_START, version, si.getId(), segmentSuffix);\n      }\n\n      if (version >= VERSION_META) {\n        packedIntsVersion = metaIn.readVInt();\n        chunkSize = metaIn.readVInt();\n      } else {\n        packedIntsVersion = vectorsStream.readVInt();\n        chunkSize = vectorsStream.readVInt();\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n\n      FieldsIndex indexReader = null;\n      long maxPointer = -1;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"tvx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong(); // the end of the data section\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), metaIn);\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.indexReader = indexReader;\n      this.maxPointer = maxPointer;\n\n      if (version >= VERSION_META) {\n        numChunks = metaIn.readVLong();\n        numDirtyChunks = metaIn.readVLong();\n      } else {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n      }\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n      }\n\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, null);\n        metaIn.close();\n      }\n\n      success = true;\n    } catch (Throwable t) {\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, t);\n        throw new AssertionError(\"unreachable\");\n      } else {\n        throw t;\n      }\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, metaIn);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    try {\n      // Open the data file and read metadata\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(vectorsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      FieldsIndex indexReader = null;\n      long maxPointer = -1;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"tvx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong(); // the end of the data section\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, VECTORS_INDEX_EXTENSION_PREFIX, VECTORS_INDEX_CODEC_NAME, si.getId());\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.indexReader = indexReader;\n      this.maxPointer = maxPointer;\n\n      long pos = vectorsStream.getFilePointer();\n      vectorsStream.seek(maxPointer);\n      numChunks = vectorsStream.readVLong();\n      numDirtyChunks = vectorsStream.readVLong();\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n      vectorsStream.seek(pos);\n\n      packedIntsVersion = vectorsStream.readVInt();\n      chunkSize = vectorsStream.readVInt();\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45264aed0cfa8a8a55ae1292b0e336d29cd88401","date":1600361948,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingTermVectorsReader#CompressingTermVectorsReader(Directory,SegmentInfo,String,FieldInfos,IOContext,String,CompressionMode).mjava","sourceNew":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    ChecksumIndexInput metaIn = null;\n    try {\n      // Open the data file\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(vectorsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      if (version >= VERSION_OFFHEAP_INDEX) {\n        final String metaStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION);\n        metaIn = d.openChecksumInput(metaStreamFN, IOContext.READONCE);\n        CodecUtil.checkIndexHeader(metaIn, VECTORS_INDEX_CODEC_NAME + \"Meta\", META_VERSION_START, version, si.getId(), segmentSuffix);\n      }\n\n      if (version >= VERSION_META) {\n        packedIntsVersion = metaIn.readVInt();\n        chunkSize = metaIn.readVInt();\n      } else {\n        packedIntsVersion = vectorsStream.readVInt();\n        chunkSize = vectorsStream.readVInt();\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n\n      FieldsIndex indexReader = null;\n      long maxPointer = -1;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"tvx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong(); // the end of the data section\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), metaIn);\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.indexReader = indexReader;\n      this.maxPointer = maxPointer;\n\n      if (version >= VERSION_META) {\n        numDirtyChunks = metaIn.readVLong();\n        numDirtyDocs = metaIn.readVLong();\n      } else {\n        // Old versions of this format did not record numDirtyDocs. Since bulk\n        // merges are disabled on version increments anyway, we make no effort\n        // to get valid values of numDirtyChunks and numDirtyDocs.\n        numDirtyChunks = numDirtyDocs = -1;\n      }\n\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, null);\n        metaIn.close();\n      }\n\n      success = true;\n    } catch (Throwable t) {\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, t);\n        throw new AssertionError(\"unreachable\");\n      } else {\n        throw t;\n      }\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, metaIn);\n      }\n    }\n  }\n\n","sourceOld":"  /** Sole constructor. */\n  public CompressingTermVectorsReader(Directory d, SegmentInfo si, String segmentSuffix, FieldInfos fn,\n      IOContext context, String formatName, CompressionMode compressionMode) throws IOException {\n    this.compressionMode = compressionMode;\n    final String segment = si.name;\n    boolean success = false;\n    fieldInfos = fn;\n    numDocs = si.maxDoc();\n\n    ChecksumIndexInput metaIn = null;\n    try {\n      // Open the data file\n      final String vectorsStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_EXTENSION);\n      vectorsStream = d.openInput(vectorsStreamFN, context);\n      version = CodecUtil.checkIndexHeader(vectorsStream, formatName, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n      assert CodecUtil.indexHeaderLength(formatName, segmentSuffix) == vectorsStream.getFilePointer();\n\n      if (version >= VERSION_OFFHEAP_INDEX) {\n        final String metaStreamFN = IndexFileNames.segmentFileName(segment, segmentSuffix, VECTORS_META_EXTENSION);\n        metaIn = d.openChecksumInput(metaStreamFN, IOContext.READONCE);\n        CodecUtil.checkIndexHeader(metaIn, VECTORS_INDEX_CODEC_NAME + \"Meta\", META_VERSION_START, version, si.getId(), segmentSuffix);\n      }\n\n      if (version >= VERSION_META) {\n        packedIntsVersion = metaIn.readVInt();\n        chunkSize = metaIn.readVInt();\n      } else {\n        packedIntsVersion = vectorsStream.readVInt();\n        chunkSize = vectorsStream.readVInt();\n      }\n\n      // NOTE: data file is too costly to verify checksum against all the bytes on open,\n      // but for now we at least verify proper structure of the checksum footer: which looks\n      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption\n      // such as file truncation.\n      CodecUtil.retrieveChecksum(vectorsStream);\n\n      FieldsIndex indexReader = null;\n      long maxPointer = -1;\n\n      if (version < VERSION_OFFHEAP_INDEX) {\n        // Load the index into memory\n        final String indexName = IndexFileNames.segmentFileName(segment, segmentSuffix, \"tvx\");\n        try (ChecksumIndexInput indexStream = d.openChecksumInput(indexName, context)) {\n          Throwable priorE = null;\n          try {\n            assert formatName.endsWith(\"Data\");\n            final String codecNameIdx = formatName.substring(0, formatName.length() - \"Data\".length()) + \"Index\";\n            final int version2 = CodecUtil.checkIndexHeader(indexStream, codecNameIdx, VERSION_START, VERSION_CURRENT, si.getId(), segmentSuffix);\n            if (version != version2) {\n              throw new CorruptIndexException(\"Version mismatch between stored fields index and data: \" + version + \" != \" + version2, indexStream);\n            }\n            assert CodecUtil.indexHeaderLength(codecNameIdx, segmentSuffix) == indexStream.getFilePointer();\n            indexReader = new LegacyFieldsIndexReader(indexStream, si);\n            maxPointer = indexStream.readVLong(); // the end of the data section\n          } catch (Throwable exception) {\n            priorE = exception;\n          } finally {\n            CodecUtil.checkFooter(indexStream, priorE);\n          }\n        }\n      } else {\n        FieldsIndexReader fieldsIndexReader = new FieldsIndexReader(d, si.name, segmentSuffix, VECTORS_INDEX_EXTENSION, VECTORS_INDEX_CODEC_NAME, si.getId(), metaIn);\n        indexReader = fieldsIndexReader;\n        maxPointer = fieldsIndexReader.getMaxPointer();\n      }\n\n      this.indexReader = indexReader;\n      this.maxPointer = maxPointer;\n\n      if (version >= VERSION_META) {\n        numChunks = metaIn.readVLong();\n        numDirtyChunks = metaIn.readVLong();\n      } else {\n        vectorsStream.seek(maxPointer);\n        numChunks = vectorsStream.readVLong();\n        numDirtyChunks = vectorsStream.readVLong();\n      }\n      if (numDirtyChunks > numChunks) {\n        throw new CorruptIndexException(\"invalid chunk counts: dirty=\" + numDirtyChunks + \", total=\" + numChunks, vectorsStream);\n      }\n\n      decompressor = compressionMode.newDecompressor();\n      this.reader = new BlockPackedReaderIterator(vectorsStream, packedIntsVersion, PACKED_BLOCK_SIZE, 0);\n\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, null);\n        metaIn.close();\n      }\n\n      success = true;\n    } catch (Throwable t) {\n      if (metaIn != null) {\n        CodecUtil.checkFooter(metaIn, t);\n        throw new AssertionError(\"unreachable\");\n      } else {\n        throw t;\n      }\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(this, metaIn);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1f3b037cd083286b2af89f96e768f85dcd8072d6":["6120217e09092280e618050d052131ebcf6802d5"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"07155cdd910937cdf6877e48884d5782845c8b8b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","eda61b1e90b490cc5837200e04c02639a0d272c7"],"6ac4bff3307e88928bf48cd1a283ff7da1f82464":["389e8bca54f58e35576077f3ff46f123b3660018"],"a78b813d9350cc28625598f6dbbb49b586a40618":["6ac4bff3307e88928bf48cd1a283ff7da1f82464"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["b88448324d3a96c5842455dabea63450b697b58f","b0267c69e2456a3477a1ad785723f2135da3117e"],"b06445ae1731e049327712db0454e5643ca9b7fe":["b88448324d3a96c5842455dabea63450b697b58f","b0267c69e2456a3477a1ad785723f2135da3117e"],"b88448324d3a96c5842455dabea63450b697b58f":["59d4661023aa9541b0a759e4d2e11dcf83b923a0"],"9bb9a29a5e71a90295f175df8919802993142c9a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","a78b813d9350cc28625598f6dbbb49b586a40618"],"59d4661023aa9541b0a759e4d2e11dcf83b923a0":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"818c86419d333447415a4e14fec4365320992e26":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"45264aed0cfa8a8a55ae1292b0e336d29cd88401":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"],"b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5":["b0267c69e2456a3477a1ad785723f2135da3117e"],"6120217e09092280e618050d052131ebcf6802d5":["818c86419d333447415a4e14fec4365320992e26"],"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"5eb2511ababf862ea11e10761c70ee560cd84510":["6120217e09092280e618050d052131ebcf6802d5","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"b0267c69e2456a3477a1ad785723f2135da3117e":["b88448324d3a96c5842455dabea63450b697b58f"],"37b84753dc1f66eba4973779932885fe42cde001":["07155cdd910937cdf6877e48884d5782845c8b8b"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["a78b813d9350cc28625598f6dbbb49b586a40618"],"4b612f3f700a1ca999f12198b7a33c65b4a96fd0":["3a88f37cd0154833b5c58daac509eb8be347d0f2"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["4b612f3f700a1ca999f12198b7a33c65b4a96fd0"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["eda61b1e90b490cc5837200e04c02639a0d272c7","37b84753dc1f66eba4973779932885fe42cde001"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"389e8bca54f58e35576077f3ff46f123b3660018":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"3a88f37cd0154833b5c58daac509eb8be347d0f2":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["45264aed0cfa8a8a55ae1292b0e336d29cd88401"]},"commit2Childs":{"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","3a88f37cd0154833b5c58daac509eb8be347d0f2"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["07155cdd910937cdf6877e48884d5782845c8b8b","d4d69c535930b5cce125cff868d40f6373dc27d4"],"07155cdd910937cdf6877e48884d5782845c8b8b":["37b84753dc1f66eba4973779932885fe42cde001"],"6ac4bff3307e88928bf48cd1a283ff7da1f82464":["a78b813d9350cc28625598f6dbbb49b586a40618"],"a78b813d9350cc28625598f6dbbb49b586a40618":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"b88448324d3a96c5842455dabea63450b697b58f":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","b0267c69e2456a3477a1ad785723f2135da3117e"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["eda61b1e90b490cc5837200e04c02639a0d272c7","07155cdd910937cdf6877e48884d5782845c8b8b"],"59d4661023aa9541b0a759e4d2e11dcf83b923a0":["b88448324d3a96c5842455dabea63450b697b58f"],"818c86419d333447415a4e14fec4365320992e26":["6120217e09092280e618050d052131ebcf6802d5"],"45264aed0cfa8a8a55ae1292b0e336d29cd88401":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6120217e09092280e618050d052131ebcf6802d5":["1f3b037cd083286b2af89f96e768f85dcd8072d6","5eb2511ababf862ea11e10761c70ee560cd84510"],"b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["45264aed0cfa8a8a55ae1292b0e336d29cd88401"],"5eb2511ababf862ea11e10761c70ee560cd84510":[],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","b7d165dc88e14a2b2f1cc4ac8133ffdde44acfd5"],"37b84753dc1f66eba4973779932885fe42cde001":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"4b612f3f700a1ca999f12198b7a33c65b4a96fd0":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["9bb9a29a5e71a90295f175df8919802993142c9a","389e8bca54f58e35576077f3ff46f123b3660018"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["818c86419d333447415a4e14fec4365320992e26"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["59d4661023aa9541b0a759e4d2e11dcf83b923a0"],"389e8bca54f58e35576077f3ff46f123b3660018":["6ac4bff3307e88928bf48cd1a283ff7da1f82464"],"3a88f37cd0154833b5c58daac509eb8be347d0f2":["4b612f3f700a1ca999f12198b7a33c65b4a96fd0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}