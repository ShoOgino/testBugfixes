{"path":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","commits":[{"id":"1816753738ff1f27f11b38030e83c0ded050b7a4","date":1380106089,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"/dev/null","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2e73db80cda3387e197641256d964f8c1c3992c7","date":1380978036,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<DocRouter.Range>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    final List<DocRouter.Range> ranges = router.partitionRange(2, shard1Range);\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc841231667f1f315bae6799c068f9aad6543967","date":1381415189,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<DocRouter.Range>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<DocRouter.Range>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9d5abf772262a05c74afddcadc95c4bdab07f1f","date":1381747682,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<DocRouter.Range>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<DocRouter.Range>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<DocRouter.Range>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<String>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"21d6ea084cd3d72cd738a74805c054e9c2bea79c","date":1400661702,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a656b32c3aa151037a8c52e9b134acc3cbf482bc","date":1400688195,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(false);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbec79839d79c818deb96450f17f87215b5659fa","date":1403810428,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding docs\", e);\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrServer.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#splitByUniqueKeyTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ShardSplitTest#splitByUniqueKeyTest().mjava","sourceNew":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","sourceOld":"  private void splitByUniqueKeyTest() throws Exception {\n    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();\n    final DocRouter router = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getRouter();\n    Slice shard1 = clusterState.getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION).getSlice(SHARD1);\n    DocRouter.Range shard1Range = shard1.getRange() != null ? shard1.getRange() : router.fullRange();\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    if (usually())  {\n      List<DocRouter.Range> ranges = router.partitionRange(4, shard1Range);\n      // 75% of range goes to shard1_0 and the rest to shard1_1\n      subRanges.add(new DocRouter.Range(ranges.get(0).min, ranges.get(2).max));\n      subRanges.add(ranges.get(3));\n    } else  {\n      subRanges = router.partitionRange(2, shard1Range);\n    }\n    final List<DocRouter.Range> ranges = subRanges;\n    final int[] docCounts = new int[ranges.size()];\n    int numReplicas = shard1.getReplicas().size();\n\n    del(\"*:*\");\n    for (int id = 0; id <= 100; id++) {\n      String shardKey = \"\" + (char)('a' + (id % 26)); // See comment in ShardRoutingTest for hash distribution\n      indexAndUpdateCount(router, ranges, docCounts, shardKey + \"!\" + String.valueOf(id), id);\n    }\n    commit();\n\n    Thread indexThread = new Thread() {\n      @Override\n      public void run() {\n        Random random = random();\n        int max = atLeast(random, 401);\n        int sleep = atLeast(random, 25);\n        log.info(\"SHARDSPLITTEST: Going to add \" + max + \" number of docs at 1 doc per \" + sleep + \"ms\");\n        Set<String> deleted = new HashSet<>();\n        for (int id = 101; id < max; id++) {\n          try {\n            indexAndUpdateCount(router, ranges, docCounts, String.valueOf(id), id);\n            Thread.sleep(sleep);\n            if (usually(random))  {\n              String delId = String.valueOf(random.nextInt(id - 101 + 1) + 101);\n              if (deleted.contains(delId))  continue;\n              try {\n                deleteAndUpdateCount(router, ranges, docCounts, delId);\n                deleted.add(delId);\n              } catch (Exception e) {\n                log.error(\"Exception while deleting docs\", e);\n              }\n            }\n          } catch (Exception e) {\n            log.error(\"Exception while adding doc id = \" + id, e);\n            // do not select this id for deletion ever\n            deleted.add(String.valueOf(id));\n          }\n        }\n      }\n    };\n    indexThread.start();\n\n    try {\n      for (int i = 0; i < 3; i++) {\n        try {\n          splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);\n          log.info(\"Layout after split: \\n\");\n          printLayout();\n          break;\n        } catch (HttpSolrClient.RemoteSolrException e) {\n          if (e.code() != 500)  {\n            throw e;\n          }\n          log.error(\"SPLITSHARD failed. \" + (i < 2 ? \" Retring split\" : \"\"), e);\n          if (i == 2) {\n            fail(\"SPLITSHARD was not successful even after three tries\");\n          }\n        }\n      }\n    } finally {\n      try {\n        indexThread.join();\n      } catch (InterruptedException e) {\n        log.error(\"Indexing thread interrupted\", e);\n      }\n    }\n\n    waitForRecoveriesToFinish(true);\n    checkDocCountsAndShardStates(docCounts, numReplicas);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["d9d5abf772262a05c74afddcadc95c4bdab07f1f"],"1816753738ff1f27f11b38030e83c0ded050b7a4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b94236357aaa22b76c10629851fe4e376e0cea82":["344b0840364d990b29b97467bfcc766ff8325d11","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"344b0840364d990b29b97467bfcc766ff8325d11":["bafca15d8e408346a67f4282ad1143b88023893b"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["344b0840364d990b29b97467bfcc766ff8325d11"],"bafca15d8e408346a67f4282ad1143b88023893b":["fbec79839d79c818deb96450f17f87215b5659fa"],"b7605579001505896d48b07160075a5c8b8e128e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","21d6ea084cd3d72cd738a74805c054e9c2bea79c"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["bafca15d8e408346a67f4282ad1143b88023893b","344b0840364d990b29b97467bfcc766ff8325d11"],"21d6ea084cd3d72cd738a74805c054e9c2bea79c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"bc841231667f1f315bae6799c068f9aad6543967":["2e73db80cda3387e197641256d964f8c1c3992c7"],"fbec79839d79c818deb96450f17f87215b5659fa":["21d6ea084cd3d72cd738a74805c054e9c2bea79c"],"2e73db80cda3387e197641256d964f8c1c3992c7":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","21d6ea084cd3d72cd738a74805c054e9c2bea79c"],"d9d5abf772262a05c74afddcadc95c4bdab07f1f":["bc841231667f1f315bae6799c068f9aad6543967"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["b7605579001505896d48b07160075a5c8b8e128e","21d6ea084cd3d72cd738a74805c054e9c2bea79c","a656b32c3aa151037a8c52e9b134acc3cbf482bc"],"1816753738ff1f27f11b38030e83c0ded050b7a4":["2e73db80cda3387e197641256d964f8c1c3992c7"],"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"344b0840364d990b29b97467bfcc766ff8325d11":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"bafca15d8e408346a67f4282ad1143b88023893b":["344b0840364d990b29b97467bfcc766ff8325d11","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"b7605579001505896d48b07160075a5c8b8e128e":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"21d6ea084cd3d72cd738a74805c054e9c2bea79c":["b7605579001505896d48b07160075a5c8b8e128e","fbec79839d79c818deb96450f17f87215b5659fa","a656b32c3aa151037a8c52e9b134acc3cbf482bc"],"bc841231667f1f315bae6799c068f9aad6543967":["d9d5abf772262a05c74afddcadc95c4bdab07f1f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1816753738ff1f27f11b38030e83c0ded050b7a4"],"fbec79839d79c818deb96450f17f87215b5659fa":["bafca15d8e408346a67f4282ad1143b88023893b"],"2e73db80cda3387e197641256d964f8c1c3992c7":["bc841231667f1f315bae6799c068f9aad6543967"],"a656b32c3aa151037a8c52e9b134acc3cbf482bc":[],"d9d5abf772262a05c74afddcadc95c4bdab07f1f":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7605579001505896d48b07160075a5c8b8e128e","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","a656b32c3aa151037a8c52e9b134acc3cbf482bc","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}