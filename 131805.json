{"path":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","commits":[{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":1,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"de3459a54b4c8751d9ef19b035577e2418064be7","date":1520297996,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"076d58da25128e8a4c511abf07c5d86c4ebddcbf","date":1523546428,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":["bccf7971a36bd151490117582a0a1a695081ead3"],"bugIntro":["69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"742168028ecb4838c124d27f836df9637be2f769","date":1529417708,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"63ae38ccbfadf7f763ed165694f6ae139e167f09","date":1529571076,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":["69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"82b686ab2904b3e81184ecea0d238b4ab0885376","date":1529576124,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9f71a1c6c905e9489b4d25c83c8d628d978a8ea","date":1538045138,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":["bccf7971a36bd151490117582a0a1a695081ead3","c5c99ad021f3da085fcb66220598a8f91dc5e453","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab6131420a270c49b653c969cc1dbbaf7d1b36e7","date":1550697886,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":["bccf7971a36bd151490117582a0a1a695081ead3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59bad1cc1e7f90125a140496e79b06afcedb68ec","date":1554915399,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e6520a21709190413a63084ed135271aab1a7c","date":1556607462,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                stateRep.name());\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n\n      for (Slice s: restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep  = r.getState();\n\n          log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\"\n              , nodeName, coreNodeName, stateRep.name());\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          ocmh.sendShardRequest(nodeName, params, shardHandler, asyncId, requestMap);\n        }\n\n        ocmh.processResponses(new NamedList(), shardHandler, true, \"REQUESTAPPLYUPDATES calls did not succeed\", asyncId, requestMap);\n\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n        if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":["076d58da25128e8a4c511abf07c5d86c4ebddcbf","bccf7971a36bd151490117582a0a1a695081ead3","63ae38ccbfadf7f763ed165694f6ae139e167f09","c5c99ad021f3da085fcb66220598a8f91dc5e453"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6681d02f2302c363be938426e68f8dfd090cc1bf","date":1575339019,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                stateRep.name());\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                stateRep.name());\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3aa683bba99315838c968fefedf3d74f44aa993","date":1575395112,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                stateRep.name());\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                stateRep.name());\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4abf821a41a2fdca2a1dea148999931d22e20529","date":1587749643,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                stateRep.name());\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86968c6cf51846df861b8f29bd85b6d9a7c9f19c","date":1591481497,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ad9c35f926b4bf8da0336d1300efc709c8d5a56","date":1591729157,"type":3,"author":"murblanc","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n          \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n          \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":["529c69423fc9de95d4d764f4c998f095fead50bd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1964c059f45ae1de1877f9f0fe3ca327ea4218e8","date":1594088246,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n          \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n          \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler(ocmh.overseer.getCoreContainer().getUpdateShardHandler().getDefaultHttpClient());\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n          \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n          \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n          \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n          \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n          \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n          \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n          \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n          \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n    \n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(),restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n          .forCollection(restoreCollectionName)\n          .forShard(sliceNames)\n          .assignNrtReplicas(numNrtReplicas)\n          .assignTlogReplicas(numTlogReplicas)\n          .assignPullReplicas(numPullReplicas)\n          .onNodes(nodeList)\n          .build();\n      Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n      Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n      List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n\n      CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        }\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n        final NamedList addReplicaResult = new NamedList();\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n          Object addResultFailure = addReplicaResult.get(\"failure\");\n          if (addResultFailure != null) {\n            SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n            if (failure == null) {\n              failure = new SimpleOrderedMap();\n              results.add(\"failure\", failure);\n            }\n            failure.addAll((NamedList) addResultFailure);\n          } else {\n            SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n            if (success == null) {\n              success = new SimpleOrderedMap();\n              results.add(\"success\", success);\n            }\n            success.addAll((NamedList) addReplicaResult.get(\"success\"));\n          }\n          countDownLatch.countDown();\n        });\n      }\n\n      boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n      if (!allIsDone) {\n        throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n      }\n      Object failures = results.get(\"failure\");\n      if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n        log.error(\"Restore failed to create initial replicas.\");\n        ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n        return;\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n        // Copy data from backed up index to each replica\n        for (Slice slice : restoreCollection.getSlices()) {\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n          params.set(NAME, \"snapshot.\" + slice.getName());\n          params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n          params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n          shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n        }\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n      }\n\n      {\n        ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n        for (Slice s : restoreCollection.getSlices()) {\n          for (Replica r : s.getReplicas()) {\n            String nodeName = r.getNodeName();\n            String coreNodeName = r.getCoreName();\n            Replica.State stateRep = r.getState();\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                  stateRep.name());\n            }\n\n            ModifiableSolrParams params = new ModifiableSolrParams();\n            params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n            params.set(CoreAdminParams.NAME, coreNodeName);\n\n            shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n          }\n\n          shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n              \"REQUESTAPPLYUPDATES calls did not succeed\");\n        }\n      }\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n      }\n\n      if (totalReplicasPerShard > 1) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n        }\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            if (log.isDebugEnabled()) {\n              log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            }\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n        log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n        ocmh.zkStateReader.aliasesManager\n            .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c526352db87264a72a7a9ad68c1b769b81e54305","date":1598780188,"type":5,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,CloudConfig,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, CloudConfig cloudConfig, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, cloudConfig, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, cloudConfig, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(cloudConfig, restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7b17e79a71117668ecbf8d3417c876e41396565","date":1598973672,"type":1,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,CloudConfig,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, CloudConfig cloudConfig, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, cloudConfig, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, cloudConfig, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(cloudConfig, restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), cloudConfig, new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d58dba38d0c9777f300cca9dd3c150fe2d244742","date":1599661188,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(repo);\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f5d9700b23e8e9b11b845fcecef89dbdf21373d9","date":1600294231,"type":3,"author":"Ilan Ginzburg","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(repo);\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategy assignStrategy = Assign.createAssignStrategy(ocmh.cloudManager, clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(repo);\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65352f844eb9e9a677ec4eb2abced4404f08181d","date":1600297608,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(repo);\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategy assignStrategy = Assign.createAssignStrategy(ocmh.cloudManager, clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(repo);\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n\n    // Test if the collection is of stateFormat 1 (i.e. not 2) supported pre Solr 9, in which case can't restore it.\n    Object format = properties.get(\"stateFormat\");\n    if (format != null && !\"2\".equals(format)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"Collection \" + backupCollection + \" is in stateFormat=\" + format +\n              \" no longer supported in Solr 9 and above. It can't be restored. If it originates in Solr 8 you can restore\" +\n              \" it there, migrate it to stateFormat=2 and backup again, it will then be restorable on Solr 9\");\n    }\n    String backupCollectionAlias = properties.getProperty(BackupManager.COLLECTION_ALIAS_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n            zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n\n    int numNrtReplicas;\n    if (message.get(REPLICATION_FACTOR) != null) {\n      numNrtReplicas = message.getInt(REPLICATION_FACTOR, 0);\n    } else if (message.get(NRT_REPLICAS) != null) {\n      numNrtReplicas = message.getInt(NRT_REPLICAS, 0);\n    } else {\n      //replicationFactor and nrtReplicas is always in sync after SOLR-11676\n      //pick from cluster state of the backed up collection\n      numNrtReplicas = backupCollectionState.getReplicationFactor();\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    assert totalReplicasPerShard > 0;\n\n    //Upload the configs\n    String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);\n    String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n            location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      propMap.put(REPLICATION_FACTOR, numNrtReplicas);\n      propMap.put(NRT_REPLICAS, numNrtReplicas);\n      propMap.put(TLOG_REPLICAS, numTlogReplicas);\n      propMap.put(PULL_REPLICAS, numPullReplicas);\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null && propMap.get(collProp) == null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(CollectionAdminParams.COLL_CONF, restoreConfigName);\n\n      // router.*\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n                  new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties(), restoreCollectionName));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    // Restore collection properties\n    backupMgr.uploadCollectionProperties(location, backupName, restoreCollectionName);\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      ocmh.overseer.offerStateUpdate(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n            .forCollection(restoreCollectionName)\n            .forShard(sliceNames)\n            .assignNrtReplicas(numNrtReplicas)\n            .assignTlogReplicas(numTlogReplicas)\n            .assignPullReplicas(numPullReplicas)\n            .onNodes(nodeList)\n            .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(ocmh.cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, restoreCollection);\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(ocmh.cloudManager, assignRequest);\n\n    CountDownLatch countDownLatch = new CountDownLatch(restoreCollection.getSlices().size());\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      }\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n                Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n      final NamedList addReplicaResult = new NamedList();\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), addReplicaResult, () -> {\n        Object addResultFailure = addReplicaResult.get(\"failure\");\n        if (addResultFailure != null) {\n          SimpleOrderedMap failure = (SimpleOrderedMap) results.get(\"failure\");\n          if (failure == null) {\n            failure = new SimpleOrderedMap();\n            results.add(\"failure\", failure);\n          }\n          failure.addAll((NamedList) addResultFailure);\n        } else {\n          SimpleOrderedMap success = (SimpleOrderedMap) results.get(\"success\");\n          if (success == null) {\n            success = new SimpleOrderedMap();\n            results.add(\"success\", success);\n          }\n          success.addAll((NamedList) addReplicaResult.get(\"success\"));\n        }\n        countDownLatch.countDown();\n      });\n    }\n\n    boolean allIsDone = countDownLatch.await(1, TimeUnit.HOURS);\n    if (!allIsDone) {\n      throw new TimeoutException(\"Initial replicas were not created within 1 hour. Timing out.\");\n    }\n    Object failures = results.get(\"failure\");\n    if (failures != null && ((SimpleOrderedMap) failures).size() > 0) {\n      log.error(\"Restore failed to create initial replicas.\");\n      ocmh.cleanupCollection(restoreCollectionName, new NamedList<Object>());\n      return;\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n      // Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n        shardRequestTracker.sliceCmd(clusterState, params, null, slice, shardHandler);\n      }\n      shardRequestTracker.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\");\n    }\n\n    {\n      ShardRequestTracker shardRequestTracker = ocmh.asyncRequestTracker(asyncId);\n\n      for (Slice s : restoreCollection.getSlices()) {\n        for (Replica r : s.getReplicas()) {\n          String nodeName = r.getNodeName();\n          String coreNodeName = r.getCoreName();\n          Replica.State stateRep = r.getState();\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Calling REQUESTAPPLYUPDATES on: nodeName={}, coreNodeName={}, state={}\", nodeName, coreNodeName,\n                    stateRep.name());\n          }\n\n          ModifiableSolrParams params = new ModifiableSolrParams();\n          params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.REQUESTAPPLYUPDATES.toString());\n          params.set(CoreAdminParams.NAME, coreNodeName);\n\n          shardRequestTracker.sendShardRequest(nodeName, params, shardHandler);\n        }\n\n        shardRequestTracker.processResponses(new NamedList(), shardHandler, true,\n                \"REQUESTAPPLYUPDATES calls did not succeed\");\n      }\n    }\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      ocmh.overseer.offerStateUpdate((Utils.toJSON(new ZkNodeProps(propMap))));\n    }\n\n    if (totalReplicasPerShard > 1) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection.getName());\n      }\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n\n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas : \"Unexpected number of replicas\";\n          }\n\n          if (log.isDebugEnabled()) {\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          }\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    if (backupCollectionAlias != null && !backupCollectionAlias.equals(backupCollection)) {\n      log.debug(\"Restoring alias {} -> {}\", backupCollectionAlias, backupCollection);\n      ocmh.zkStateReader.aliasesManager\n              .applyModificationAndExportToZk(a -> a.cloneWithCollectionAlias(backupCollectionAlias, backupCollection));\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3aa683bba99315838c968fefedf3d74f44aa993":["69e6520a21709190413a63084ed135271aab1a7c","6681d02f2302c363be938426e68f8dfd090cc1bf"],"b94236357aaa22b76c10629851fe4e376e0cea82":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"1964c059f45ae1de1877f9f0fe3ca327ea4218e8":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"f5d9700b23e8e9b11b845fcecef89dbdf21373d9":["d58dba38d0c9777f300cca9dd3c150fe2d244742"],"c526352db87264a72a7a9ad68c1b769b81e54305":["3f504512a03d978990cbff30db0522b354e846db"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["e9f71a1c6c905e9489b4d25c83c8d628d978a8ea"],"82b686ab2904b3e81184ecea0d238b4ab0885376":["63ae38ccbfadf7f763ed165694f6ae139e167f09"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["1964c059f45ae1de1877f9f0fe3ca327ea4218e8"],"6681d02f2302c363be938426e68f8dfd090cc1bf":["69e6520a21709190413a63084ed135271aab1a7c"],"076d58da25128e8a4c511abf07c5d86c4ebddcbf":["de3459a54b4c8751d9ef19b035577e2418064be7"],"ab6131420a270c49b653c969cc1dbbaf7d1b36e7":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["076d58da25128e8a4c511abf07c5d86c4ebddcbf","82b686ab2904b3e81184ecea0d238b4ab0885376"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["076d58da25128e8a4c511abf07c5d86c4ebddcbf","82b686ab2904b3e81184ecea0d238b4ab0885376"],"e7b17e79a71117668ecbf8d3417c876e41396565":["c526352db87264a72a7a9ad68c1b769b81e54305"],"5ad9c35f926b4bf8da0336d1300efc709c8d5a56":["86968c6cf51846df861b8f29bd85b6d9a7c9f19c"],"3f504512a03d978990cbff30db0522b354e846db":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"59bad1cc1e7f90125a140496e79b06afcedb68ec":["ab6131420a270c49b653c969cc1dbbaf7d1b36e7"],"e9f71a1c6c905e9489b4d25c83c8d628d978a8ea":["82b686ab2904b3e81184ecea0d238b4ab0885376"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"65352f844eb9e9a677ec4eb2abced4404f08181d":["d58dba38d0c9777f300cca9dd3c150fe2d244742","f5d9700b23e8e9b11b845fcecef89dbdf21373d9"],"63ae38ccbfadf7f763ed165694f6ae139e167f09":["742168028ecb4838c124d27f836df9637be2f769"],"742168028ecb4838c124d27f836df9637be2f769":["076d58da25128e8a4c511abf07c5d86c4ebddcbf"],"4abf821a41a2fdca2a1dea148999931d22e20529":["6681d02f2302c363be938426e68f8dfd090cc1bf"],"86968c6cf51846df861b8f29bd85b6d9a7c9f19c":["4abf821a41a2fdca2a1dea148999931d22e20529"],"69e6520a21709190413a63084ed135271aab1a7c":["59bad1cc1e7f90125a140496e79b06afcedb68ec"],"de3459a54b4c8751d9ef19b035577e2418064be7":["b94236357aaa22b76c10629851fe4e376e0cea82"],"d58dba38d0c9777f300cca9dd3c150fe2d244742":["e7b17e79a71117668ecbf8d3417c876e41396565"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["65352f844eb9e9a677ec4eb2abced4404f08181d"]},"commit2Childs":{"d3aa683bba99315838c968fefedf3d74f44aa993":[],"b94236357aaa22b76c10629851fe4e376e0cea82":["de3459a54b4c8751d9ef19b035577e2418064be7"],"1964c059f45ae1de1877f9f0fe3ca327ea4218e8":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"f5d9700b23e8e9b11b845fcecef89dbdf21373d9":["65352f844eb9e9a677ec4eb2abced4404f08181d"],"c526352db87264a72a7a9ad68c1b769b81e54305":["e7b17e79a71117668ecbf8d3417c876e41396565"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["ab6131420a270c49b653c969cc1dbbaf7d1b36e7"],"82b686ab2904b3e81184ecea0d238b4ab0885376":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","e9f71a1c6c905e9489b4d25c83c8d628d978a8ea"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["3f504512a03d978990cbff30db0522b354e846db"],"6681d02f2302c363be938426e68f8dfd090cc1bf":["d3aa683bba99315838c968fefedf3d74f44aa993","4abf821a41a2fdca2a1dea148999931d22e20529"],"076d58da25128e8a4c511abf07c5d86c4ebddcbf":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","742168028ecb4838c124d27f836df9637be2f769"],"ab6131420a270c49b653c969cc1dbbaf7d1b36e7":["59bad1cc1e7f90125a140496e79b06afcedb68ec"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[],"e7b17e79a71117668ecbf8d3417c876e41396565":["d58dba38d0c9777f300cca9dd3c150fe2d244742"],"5ad9c35f926b4bf8da0336d1300efc709c8d5a56":["1964c059f45ae1de1877f9f0fe3ca327ea4218e8"],"3f504512a03d978990cbff30db0522b354e846db":["c526352db87264a72a7a9ad68c1b769b81e54305"],"59bad1cc1e7f90125a140496e79b06afcedb68ec":["69e6520a21709190413a63084ed135271aab1a7c"],"e9f71a1c6c905e9489b4d25c83c8d628d978a8ea":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"65352f844eb9e9a677ec4eb2abced4404f08181d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"63ae38ccbfadf7f763ed165694f6ae139e167f09":["82b686ab2904b3e81184ecea0d238b4ab0885376"],"742168028ecb4838c124d27f836df9637be2f769":["63ae38ccbfadf7f763ed165694f6ae139e167f09"],"4abf821a41a2fdca2a1dea148999931d22e20529":["86968c6cf51846df861b8f29bd85b6d9a7c9f19c"],"69e6520a21709190413a63084ed135271aab1a7c":["d3aa683bba99315838c968fefedf3d74f44aa993","6681d02f2302c363be938426e68f8dfd090cc1bf"],"86968c6cf51846df861b8f29bd85b6d9a7c9f19c":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"de3459a54b4c8751d9ef19b035577e2418064be7":["076d58da25128e8a4c511abf07c5d86c4ebddcbf"],"d58dba38d0c9777f300cca9dd3c150fe2d244742":["f5d9700b23e8e9b11b845fcecef89dbdf21373d9","65352f844eb9e9a677ec4eb2abced4404f08181d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3aa683bba99315838c968fefedf3d74f44aa993","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}