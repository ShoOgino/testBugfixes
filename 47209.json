{"path":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"modules/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ed50c8be6f41a006d8f93268765de9ad91908419","date":1340353054,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["4107dd39b127d892359c5c1d67d0f14d92f1a9bf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, 0);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":["4107dd39b127d892359c5c1d67d0f14d92f1a9bf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, 0);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, 0);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, false);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a09f425f56a7c259e0e5b4ee07cdc1ea592317f","date":1348548055,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekExact(br,true)) {\n          docs = termsEnum.docs(acceptDocs, docs, 0);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekCeil(br) == TermsEnum.SeekStatus.FOUND) {\n          docs = termsEnum.docs(acceptDocs, docs, 0);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["4107dd39b127d892359c5c1d67d0f14d92f1a9bf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4107dd39b127d892359c5c1d67d0f14d92f1a9bf","date":1351689723,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, 0); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    /*\n     * TODO: we should explore if it is worth to build the union of the terms in\n     * an automaton an call intersect on the termsenum if the density is high\n     */\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    AtomicReader reader = context.reader();\n    FixedBitSet result = new FixedBitSet(reader.maxDoc());\n    Fields fields = reader.fields();\n\n    if (fields == null) {\n      return result;\n    }\n\n    BytesRef br = new BytesRef();\n    String lastField = null;\n    Terms termsC;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (Term term : terms) {\n      if (!term.field().equals(lastField)) {\n        termsC = fields.terms(term.field());\n        if (termsC == null) {\n          return result;\n        }\n        termsEnum = termsC.iterator(null);\n        lastField = term.field();\n      }\n\n      if (terms != null) { // TODO this check doesn't make sense, decide which variable its supposed to be for\n        br.copyBytes(term.bytes());\n        assert termsEnum != null;\n        if (termsEnum.seekExact(br,true)) {\n          docs = termsEnum.docs(acceptDocs, docs, 0);\n          while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n            result.set(docs.docID());\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":["e6e919043fa85ee891123768dd655a98edbbf63c","02331260bb246364779cb6f04919ca47900d01bb","f08557cdb6c60ac7b88a9342c983a20cd236e74f","ed50c8be6f41a006d8f93268765de9ad91908419","e141595402370bee958745de8b1c9de1fa182581","3cc749c053615f5871f3b95715fe292f34e70a53","da6d5ac19a80d65b1e864251f155d30960353b7e","e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","28427ef110c4c5bf5b4057731b83110bd1e13724","edc9ac4bba51b8acbb06a7fcd75347f7fb8b10d9","7a09f425f56a7c259e0e5b4ee07cdc1ea592317f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec644d012bae925b8aa2f0af238e43ea498b59ac","date":1351957726,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, 0); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, 0); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    /*\n     * TODO: we should explore if it is worth to build the union of the terms in\n     * an automaton an call intersect on the termsenum if the density is high\n     */\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, 0); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, 0); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8","date":1373996650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare, false)) { // don't use cache since we could pollute the cache here easily\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":4,"author":"Ryan Ernst","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"  @Override\n  public DocIdSet getDocIdSet(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n    final AtomicReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["ec644d012bae925b8aa2f0af238e43ea498b59ac","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"ec644d012bae925b8aa2f0af238e43ea498b59ac":["4107dd39b127d892359c5c1d67d0f14d92f1a9bf"],"4107dd39b127d892359c5c1d67d0f14d92f1a9bf":["7a09f425f56a7c259e0e5b4ee07cdc1ea592317f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ed50c8be6f41a006d8f93268765de9ad91908419":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["ec644d012bae925b8aa2f0af238e43ea498b59ac"],"7a09f425f56a7c259e0e5b4ee07cdc1ea592317f":["02331260bb246364779cb6f04919ca47900d01bb"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b89678825b68eccaf09e6ab71675fc0b0af1e099","ed50c8be6f41a006d8f93268765de9ad91908419"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["fe33227f6805edab2036cbb80645cc4e2d1fa424","02331260bb246364779cb6f04919ca47900d01bb"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["ed50c8be6f41a006d8f93268765de9ad91908419","02331260bb246364779cb6f04919ca47900d01bb"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"02331260bb246364779cb6f04919ca47900d01bb":["ed50c8be6f41a006d8f93268765de9ad91908419"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ec644d012bae925b8aa2f0af238e43ea498b59ac":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"4107dd39b127d892359c5c1d67d0f14d92f1a9bf":["ec644d012bae925b8aa2f0af238e43ea498b59ac"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ed50c8be6f41a006d8f93268765de9ad91908419","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"ed50c8be6f41a006d8f93268765de9ad91908419":["fe33227f6805edab2036cbb80645cc4e2d1fa424","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"7a09f425f56a7c259e0e5b4ee07cdc1ea592317f":["4107dd39b127d892359c5c1d67d0f14d92f1a9bf"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"02331260bb246364779cb6f04919ca47900d01bb":["7a09f425f56a7c259e0e5b4ee07cdc1ea592317f","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}