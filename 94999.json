{"path":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","commits":[{"id":"b1405362241b561f5590ff4a87d5d6e173bcd9cf","date":1190107634,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"/dev/null","sourceNew":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n    docWriter.pauseAllThreads();\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null)\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            int delCount = applyDeletes(flushDocs);\n            if (infoStream != null)\n              infoStream.println(\"flushed \" + delCount + \" deleted documents\");\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort();\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["83bbb041887bbef07b8a98d08a0e1713ce137039","5a251aa47d1808cbae42c0e172d698c377430e60","cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2e0d75d47683f1bcf4a7c6de9d79ac3b91de51c4","date":1190750527,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n    docWriter.pauseAllThreads();\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            int delCount = applyDeletes(flushDocs);\n            if (infoStream != null)\n              infoStream.println(\"flushed \" + delCount + \" deleted documents\");\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort();\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n    docWriter.pauseAllThreads();\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null)\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            int delCount = applyDeletes(flushDocs);\n            if (infoStream != null)\n              infoStream.println(\"flushed \" + delCount + \" deleted documents\");\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort();\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a251aa47d1808cbae42c0e172d698c377430e60","date":1199375390,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n    docWriter.pauseAllThreads();\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            applyDeletes(flushDocs);\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort();\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n    docWriter.pauseAllThreads();\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            int delCount = applyDeletes(flushDocs);\n            if (infoStream != null)\n              infoStream.println(\"flushed \" + delCount + \" deleted documents\");\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort();\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"83bbb041887bbef07b8a98d08a0e1713ce137039","date":1200330381,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            applyDeletes(flushDocs);\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort(null);\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n    docWriter.pauseAllThreads();\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            applyDeletes(flushDocs);\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort();\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1fd1f3c5c06036aebe90bc6da756a37d03f63884","date":1200847858,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            applyDeletes(flushDocs);\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort(null);\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            applyDeletes(flushDocs);\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort(null);\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e82780afe6097066eb5befb86e9432f077667e3d","date":1202756169,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    flushCount++;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      if (flushDeletes) {\n        try {\n          SegmentInfos rollback = (SegmentInfos) segmentInfos.clone();\n\n          boolean success = false;\n          try {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments only when a commit()\n            // finally happens\n            applyDeletes(newSegment);\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception flushing deletes\");\n                \n              // Carefully remove any partially written .del\n              // files\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Remove just flushed segment\n              deleter.refresh(segment);\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n            }              \n          }\n        } finally {\n          // Regardless of success of failure in flushing\n          // deletes, we must clear them from our buffer:\n          docWriter.clearBufferedDeletes();\n        }\n      }\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDocs || flushDeletes)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n      \n      return flushDocs || flushDeletes;\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docWriter.getDocStoreOffset() +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs || flushDeletes) {\n\n        SegmentInfos rollback = null;\n\n        if (flushDeletes)\n          rollback = (SegmentInfos) segmentInfos.clone();\n\n        boolean success = false;\n\n        try {\n          if (flushDocs) {\n\n            if (0 == docStoreOffset && flushDocStores) {\n              // This means we are flushing private doc stores\n              // with this segment, so it will not be shared\n              // with other segments\n              assert docStoreSegment != null;\n              assert docStoreSegment.equals(segment);\n              docStoreOffset = -1;\n              docStoreIsCompoundFile = false;\n              docStoreSegment = null;\n            }\n\n            int flushedDocCount = docWriter.flush(flushDocStores);\n          \n            newSegment = new SegmentInfo(segment,\n                                         flushedDocCount,\n                                         directory, false, true,\n                                         docStoreOffset, docStoreSegment,\n                                         docStoreIsCompoundFile);\n            segmentInfos.addElement(newSegment);\n          }\n\n          if (flushDeletes) {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments, when\n            // autoCommit=false\n            applyDeletes(flushDocs);\n            doAfterFlush();\n          }\n\n          checkpoint();\n          success = true;\n        } finally {\n          if (!success) {\n\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n                \n            if (flushDeletes) {\n\n              // Carefully check if any partial .del files\n              // should be removed:\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n              \n            } else {\n              // Remove segment we added, if any:\n              if (newSegment != null && \n                  segmentInfos.size() > 0 && \n                  segmentInfos.info(segmentInfos.size()-1) == newSegment)\n                segmentInfos.remove(segmentInfos.size()-1);\n            }\n            if (flushDocs)\n              docWriter.abort(null);\n            deletePartialSegmentsFile();\n            deleter.checkpoint(segmentInfos, false);\n\n            if (segment != null)\n              deleter.refresh(segment);\n          }\n        }\n\n        deleter.checkpoint(segmentInfos, autoCommit);\n\n        if (flushDocs && mergePolicy.useCompoundFile(segmentInfos,\n                                                     newSegment)) {\n          success = false;\n          try {\n            docWriter.createCompoundFile(segment);\n            newSegment.setUseCompoundFile(true);\n            checkpoint();\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception creating compound file for newly flushed segment \" + segment);\n              newSegment.setUseCompoundFile(false);\n              deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n              deletePartialSegmentsFile();\n            }\n          }\n\n          deleter.checkpoint(segmentInfos, autoCommit);\n        }\n      \n        return true;\n      } else {\n        return false;\n      }\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5","4ab2938d01fe23337bcad36c5ad7207deb33a6a4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63","date":1204234542,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    flushCount++;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      if (flushDeletes) {\n        try {\n          SegmentInfos rollback = (SegmentInfos) segmentInfos.clone();\n\n          boolean success = false;\n          try {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments only when a commit()\n            // finally happens\n            applyDeletes(newSegment);\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception flushing deletes\");\n                \n              // Carefully remove any partially written .del\n              // files\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Remove just flushed segment\n              deleter.refresh(segment);\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n            }              \n          }\n        } finally {\n          // Regardless of success of failure in flushing\n          // deletes, we must clear them from our buffer:\n          docWriter.clearBufferedDeletes();\n        }\n      }\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDocs || flushDeletes)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n      \n      return flushDocs || flushDeletes;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    flushCount++;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      if (flushDeletes) {\n        try {\n          SegmentInfos rollback = (SegmentInfos) segmentInfos.clone();\n\n          boolean success = false;\n          try {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments only when a commit()\n            // finally happens\n            applyDeletes(newSegment);\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception flushing deletes\");\n                \n              // Carefully remove any partially written .del\n              // files\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Remove just flushed segment\n              deleter.refresh(segment);\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n            }              \n          }\n        } finally {\n          // Regardless of success of failure in flushing\n          // deletes, we must clear them from our buffer:\n          docWriter.clearBufferedDeletes();\n        }\n      }\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDocs || flushDeletes)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n      \n      return flushDocs || flushDeletes;\n\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    if (autoCommit)\n      flushDeletes = true;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      if (flushDocs)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    flushCount++;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      if (flushDeletes) {\n        try {\n          SegmentInfos rollback = (SegmentInfos) segmentInfos.clone();\n\n          boolean success = false;\n          try {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments only when a commit()\n            // finally happens\n            applyDeletes(newSegment);\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception flushing deletes\");\n                \n              // Carefully remove any partially written .del\n              // files\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Remove just flushed segment\n              deleter.refresh(segment);\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n            }              \n          }\n        } finally {\n          // Regardless of success of failure in flushing\n          // deletes, we must clear them from our buffer:\n          docWriter.clearBufferedDeletes();\n        }\n      }\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDocs || flushDeletes)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n      \n      return flushDocs || flushDeletes;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1fd1f3c5c06036aebe90bc6da756a37d03f63884":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"83bbb041887bbef07b8a98d08a0e1713ce137039":["5a251aa47d1808cbae42c0e172d698c377430e60"],"2e0d75d47683f1bcf4a7c6de9d79ac3b91de51c4":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63":["e82780afe6097066eb5befb86e9432f077667e3d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5a251aa47d1808cbae42c0e172d698c377430e60":["2e0d75d47683f1bcf4a7c6de9d79ac3b91de51c4"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"e82780afe6097066eb5befb86e9432f077667e3d":["1fd1f3c5c06036aebe90bc6da756a37d03f63884"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"]},"commit2Childs":{"1fd1f3c5c06036aebe90bc6da756a37d03f63884":["e82780afe6097066eb5befb86e9432f077667e3d"],"83bbb041887bbef07b8a98d08a0e1713ce137039":["1fd1f3c5c06036aebe90bc6da756a37d03f63884"],"2e0d75d47683f1bcf4a7c6de9d79ac3b91de51c4":["5a251aa47d1808cbae42c0e172d698c377430e60"],"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["2e0d75d47683f1bcf4a7c6de9d79ac3b91de51c4"],"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"5a251aa47d1808cbae42c0e172d698c377430e60":["83bbb041887bbef07b8a98d08a0e1713ce137039"],"e82780afe6097066eb5befb86e9432f077667e3d":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}