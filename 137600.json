{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","commits":[{"id":"eb378f8bdee16a26810e086303a4a86b4930ea12","date":1296410797,"type":2,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexReader#reopen(IndexWriter).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} (an internal IndexWriter operation) and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  public IndexReader reopen(IndexWriter writer) throws CorruptIndexException, IOException {\n    return writer.getReader();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69a6d2d525aeab53c867ed26934185e5bb627d0e","date":1296516902,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n    \n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n    \n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":2,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexReader#reopen(IndexWriter).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} (an internal IndexWriter operation) and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link IndexWriterConfig#setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  public IndexReader reopen(IndexWriter writer) throws CorruptIndexException, IOException {\n    return writer.getReader();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"327863a2fd61e831028b6c56c8fef6b00a44eb0b","date":1302686439,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    flush(false, applyAllDeletes); // don't sync on IW here DWPT will deadlock\n    synchronized(this) {\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":["7d45e9e2ad7f57776540627c78f5e22e469ccdc1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7d45e9e2ad7f57776540627c78f5e22e469ccdc1","date":1302784878,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean maybeMerge;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        maybeMerge = docWriter.flushAllThreads(applyAllDeletes);\n        if (!maybeMerge) {\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // now we are done - finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if(maybeMerge) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    flush(false, applyAllDeletes); // don't sync on IW here DWPT will deadlock\n    synchronized(this) {\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":["327863a2fd61e831028b6c56c8fef6b00a44eb0b","eb378f8bdee16a26810e086303a4a86b4930ea12"],"bugIntro":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6f4cae61e16730201371ab7e9912721c19324e7","date":1303199575,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean maybeMerge;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        maybeMerge = docWriter.flushAllThreads(applyAllDeletes);\n        if (!maybeMerge) {\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if(maybeMerge) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean maybeMerge;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        maybeMerge = docWriter.flushAllThreads(applyAllDeletes);\n        if (!maybeMerge) {\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // now we are done - finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if(maybeMerge) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fcef5771aee556e6c886946095ae4485a392526b","date":1304005192,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if(anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean maybeMerge;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        maybeMerge = docWriter.flushAllThreads(applyAllDeletes);\n        if (!maybeMerge) {\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if(maybeMerge) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1b1414bb9669ffe06a89e46b889729f2e2588081","date":1304006610,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if(anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n    \n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n    \n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n    \n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n\n    // Prevent segmentInfos from changing while opening the\n    // reader; in theory we could do similar retry logic,\n    // just like we do when loading segments_N\n    IndexReader r;\n    synchronized(this) {\n      flush(false, applyAllDeletes);\n      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n      if (infoStream != null) {\n        message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n      }\n    }\n    maybeMerge();\n\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0061262413ecc163d6eebba1b5c43ab91a0c2dc5","date":1311195279,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c00afe74a80796ed1f30a9509b150ff104746a1f","date":1312881735,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    final boolean anySegmentFlushed;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during while NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":["fcef5771aee556e6c886946095ae4485a392526b","7d45e9e2ad7f57776540627c78f5e22e469ccdc1"],"bugIntro":["e4f3b0a30c9d521b86f768348f832af93505b4eb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, codecs, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream != null) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream != null) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      message(\"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream != null) {\n            message(\"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream != null) {\n          message(\"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      message(\"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"58c6bbc222f074c844e736e6fb23647e3db9cfe3","date":1322743940,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream != null) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream != null) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d118cdb655aab0c33b7e9cc4eea0cfae44a2701f","date":1322855559,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4","date":1323543613,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5df35ab57c223ea11aec64b53bf611904f3dced","date":1323640545,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    infoStream.message(\"IW\", \"flush at getReader\");\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = new DirectoryReader(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success && infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception during NRT reader\");\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2725b2d479964ea5aaea0ba4ae2634716f3ec26c","date":1327188170,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  IndexReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final IndexReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d7bbf8cffd2321f26cf9f6487f1571d325f20bc3","date":1328092914,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = DirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#getReader(boolean).mjava","sourceNew":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","sourceOld":"  /**\n   * Expert: returns a readonly reader, covering all\n   * committed as well as un-committed changes to the index.\n   * This provides \"near real-time\" searching, in that\n   * changes made during an IndexWriter session can be\n   * quickly made available for searching without closing\n   * the writer nor calling {@link #commit}.\n   *\n   * <p>Note that this is functionally equivalent to calling\n   * {#flush} and then using {@link IndexReader#open} to\n   * open a new reader.  But the turnaround time of this\n   * method should be faster since it avoids the potentially\n   * costly {@link #commit}.</p>\n   *\n   * <p>You must close the {@link IndexReader} returned by\n   * this method once you are done using it.</p>\n   *\n   * <p>It's <i>near</i> real-time because there is no hard\n   * guarantee on how quickly you can get a new reader after\n   * making changes with IndexWriter.  You'll have to\n   * experiment in your situation to determine if it's\n   * fast enough.  As this is a new and experimental\n   * feature, please report back on your findings so we can\n   * learn, improve and iterate.</p>\n   *\n   * <p>The resulting reader supports {@link\n   * IndexReader#reopen}, but that call will simply forward\n   * back to this method (though this may change in the\n   * future).</p>\n   *\n   * <p>The very first time this method is called, this\n   * writer instance will make every effort to pool the\n   * readers that it opens for doing merges, applying\n   * deletes, etc.  This means additional resources (RAM,\n   * file descriptors, CPU time) will be consumed.</p>\n   *\n   * <p>For lower latency on reopening a reader, you should\n   * call {@link #setMergedSegmentWarmer} to\n   * pre-warm a newly merged segment before it's committed\n   * to the index.  This is important for minimizing\n   * index-to-search delay after a large merge.  </p>\n   *\n   * <p>If an addIndexes* call is running in another thread,\n   * then this reader will only search those segments from\n   * the foreign index that have been successfully copied\n   * over, so far</p>.\n   *\n   * <p><b>NOTE</b>: Once the writer is closed, any\n   * outstanding readers may continue to be used.  However,\n   * if you attempt to reopen any of those readers, you'll\n   * hit an {@link AlreadyClosedException}.</p>\n   *\n   * @lucene.experimental\n   *\n   * @return IndexReader that covers entire index plus all\n   * changes made so far by this IndexWriter instance\n   *\n   * @throws IOException\n   */\n  DirectoryReader getReader(boolean applyAllDeletes) throws IOException {\n    ensureOpen();\n\n    final long tStart = System.currentTimeMillis();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"flush at getReader\");\n    }\n    // Do this up front before flushing so that the readers\n    // obtained during this flush are pooled, the first time\n    // this method is called:\n    poolReaders = true;\n    final DirectoryReader r;\n    doBeforeFlush();\n    boolean anySegmentFlushed = false;\n    /*\n     * for releasing a NRT reader we must ensure that \n     * DW doesn't add any segments or deletes until we are\n     * done with creating the NRT DirectoryReader. \n     * We release the two stage full flush after we are done opening the\n     * directory reader!\n     */\n    synchronized (fullFlushLock) {\n      boolean success = false;\n      try {\n        anySegmentFlushed = docWriter.flushAllThreads();\n        if (!anySegmentFlushed) {\n          // prevent double increment since docWriter#doFlush increments the flushcount\n          // if we flushed anything.\n          flushCount.incrementAndGet();\n        }\n        success = true;\n        // Prevent segmentInfos from changing while opening the\n        // reader; in theory we could do similar retry logic,\n        // just like we do when loading segments_N\n        synchronized(this) {\n          maybeApplyDeletes(applyAllDeletes);\n          r = StandardDirectoryReader.open(this, segmentInfos, applyAllDeletes);\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"return reader version=\" + r.getVersion() + \" reader=\" + r);\n          }\n        }\n      } catch (OutOfMemoryError oom) {\n        handleOOM(oom, \"getReader\");\n        // never reached but javac disagrees:\n        return null;\n      } finally {\n        if (!success) {\n          if (infoStream.isEnabled(\"IW\")) {\n            infoStream.message(\"IW\", \"hit exception during NRT reader\");\n          }\n        }\n        // Done: finish the full flush!\n        docWriter.finishFullFlush(success);\n        doAfterFlush();\n      }\n    }\n    if (anySegmentFlushed) {\n      maybeMerge();\n    }\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"getReader took \" + (System.currentTimeMillis() - tStart) + \" msec\");\n    }\n    return r;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c5df35ab57c223ea11aec64b53bf611904f3dced":["6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4"],"58c6bbc222f074c844e736e6fb23647e3db9cfe3":["06584e6e98d592b34e1329b384182f368d2025e8"],"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"1b1414bb9669ffe06a89e46b889729f2e2588081":["fcef5771aee556e6c886946095ae4485a392526b"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d7bbf8cffd2321f26cf9f6487f1571d325f20bc3"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["d118cdb655aab0c33b7e9cc4eea0cfae44a2701f","c5df35ab57c223ea11aec64b53bf611904f3dced"],"fcef5771aee556e6c886946095ae4485a392526b":["f6f4cae61e16730201371ab7e9912721c19324e7"],"f6f4cae61e16730201371ab7e9912721c19324e7":["7d45e9e2ad7f57776540627c78f5e22e469ccdc1"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5"],"d7bbf8cffd2321f26cf9f6487f1571d325f20bc3":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4":["d118cdb655aab0c33b7e9cc4eea0cfae44a2701f"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","69a6d2d525aeab53c867ed26934185e5bb627d0e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"69a6d2d525aeab53c867ed26934185e5bb627d0e":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","69a6d2d525aeab53c867ed26934185e5bb627d0e"],"d118cdb655aab0c33b7e9cc4eea0cfae44a2701f":["58c6bbc222f074c844e736e6fb23647e3db9cfe3"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["c5df35ab57c223ea11aec64b53bf611904f3dced"],"06584e6e98d592b34e1329b384182f368d2025e8":["7b91922b55d15444d554721b352861d028eb8278"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["69a6d2d525aeab53c867ed26934185e5bb627d0e","1b1414bb9669ffe06a89e46b889729f2e2588081"],"327863a2fd61e831028b6c56c8fef6b00a44eb0b":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["c5df35ab57c223ea11aec64b53bf611904f3dced","2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"7b91922b55d15444d554721b352861d028eb8278":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"7d45e9e2ad7f57776540627c78f5e22e469ccdc1":["327863a2fd61e831028b6c56c8fef6b00a44eb0b"],"a3776dccca01c11e7046323cfad46a3b4a471233":["69a6d2d525aeab53c867ed26934185e5bb627d0e","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"c5df35ab57c223ea11aec64b53bf611904f3dced":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","2725b2d479964ea5aaea0ba4ae2634716f3ec26c","5cab9a86bd67202d20b6adc463008c8e982b070a"],"58c6bbc222f074c844e736e6fb23647e3db9cfe3":["d118cdb655aab0c33b7e9cc4eea0cfae44a2701f"],"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"1b1414bb9669ffe06a89e46b889729f2e2588081":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"fcef5771aee556e6c886946095ae4485a392526b":["1b1414bb9669ffe06a89e46b889729f2e2588081"],"f6f4cae61e16730201371ab7e9912721c19324e7":["fcef5771aee556e6c886946095ae4485a392526b"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["7b91922b55d15444d554721b352861d028eb8278"],"d7bbf8cffd2321f26cf9f6487f1571d325f20bc3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4":["c5df35ab57c223ea11aec64b53bf611904f3dced"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","eb378f8bdee16a26810e086303a4a86b4930ea12"],"69a6d2d525aeab53c867ed26934185e5bb627d0e":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","b3e06be49006ecac364d39d12b9c9f74882f9b9f","a3776dccca01c11e7046323cfad46a3b4a471233"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["327863a2fd61e831028b6c56c8fef6b00a44eb0b"],"d118cdb655aab0c33b7e9cc4eea0cfae44a2701f":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"06584e6e98d592b34e1329b384182f368d2025e8":["58c6bbc222f074c844e736e6fb23647e3db9cfe3"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"327863a2fd61e831028b6c56c8fef6b00a44eb0b":["7d45e9e2ad7f57776540627c78f5e22e469ccdc1"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["69a6d2d525aeab53c867ed26934185e5bb627d0e"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["d7bbf8cffd2321f26cf9f6487f1571d325f20bc3"],"7d45e9e2ad7f57776540627c78f5e22e469ccdc1":["f6f4cae61e16730201371ab7e9912721c19324e7"],"7b91922b55d15444d554721b352861d028eb8278":["06584e6e98d592b34e1329b384182f368d2025e8"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}