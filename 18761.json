{"path":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Query,Filter,HitCollector).mjava","commits":[{"id":"82dc8f80042322d1c443b6c70bdec5249eb745c2","date":1074623829,"type":0,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Query,Filter,HitCollector).mjava","pathOld":"/dev/null","sourceNew":"\t/** Lower-level search API.\n\t *\n\t * <p>{@link HitCollector#collect(int,float)} is called for every non-zero\n\t * scoring document.\n\t *\n\t * <p>Applications should only use this if they need <i>all</i> of the\n\t * matching documents.  The high-level search API ({@link\n\t * Searcher#search(Query)}) is usually more efficient, as it skips\n\t * non-high-scoring hits.\n\t *\n\t * @param query to match documents\n\t * @param filter if non-null, a bitset used to eliminate some documents\n\t * @param results to receive hits\n\t * \n\t * TODO: parallelize this one too\n\t */\n\tpublic void search(Query query, Filter filter, final HitCollector results)\n\t\tthrows IOException {\n\t\tfor (int i = 0; i < searchables.length; i++) {\n\n\t\t\tfinal int start = starts[i];\n\n\t\t\tsearchables[i].search(query, filter, new HitCollector() {\n\t\t\t\tpublic void collect(int doc, float score) {\n\t\t\t\t\tresults.collect(doc + start, score);\n\t\t\t\t}\n\t\t\t});\n\n\t\t}\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6691cb6747f9e850337c706c06b92e9ddf816e1","date":1077044431,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Query,Filter,HitCollector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Query,Filter,HitCollector).mjava","sourceNew":"  /** Lower-level search API.\n   *\n   * <p>{@link HitCollector#collect(int,float)} is called for every non-zero\n   * scoring document.\n   *\n   * <p>Applications should only use this if they need <i>all</i> of the\n   * matching documents.  The high-level search API ({@link\n   * Searcher#search(Query)}) is usually more efficient, as it skips\n   * non-high-scoring hits.\n   *\n   * @param query to match documents\n   * @param filter if non-null, a bitset used to eliminate some documents\n   * @param results to receive hits\n   * \n   * TODO: parallelize this one too\n   */\n  public void search(Query query, Filter filter, final HitCollector results)\n    throws IOException {\n    for (int i = 0; i < searchables.length; i++) {\n\n      final int start = starts[i];\n\n      searchables[i].search(query, filter, new HitCollector() {\n          public void collect(int doc, float score) {\n            results.collect(doc + start, score);\n          }\n        });\n\n    }\n  }\n\n","sourceOld":"\t/** Lower-level search API.\n\t *\n\t * <p>{@link HitCollector#collect(int,float)} is called for every non-zero\n\t * scoring document.\n\t *\n\t * <p>Applications should only use this if they need <i>all</i> of the\n\t * matching documents.  The high-level search API ({@link\n\t * Searcher#search(Query)}) is usually more efficient, as it skips\n\t * non-high-scoring hits.\n\t *\n\t * @param query to match documents\n\t * @param filter if non-null, a bitset used to eliminate some documents\n\t * @param results to receive hits\n\t * \n\t * TODO: parallelize this one too\n\t */\n\tpublic void search(Query query, Filter filter, final HitCollector results)\n\t\tthrows IOException {\n\t\tfor (int i = 0; i < searchables.length; i++) {\n\n\t\t\tfinal int start = starts[i];\n\n\t\t\tsearchables[i].search(query, filter, new HitCollector() {\n\t\t\t\tpublic void collect(int doc, float score) {\n\t\t\t\t\tresults.collect(doc + start, score);\n\t\t\t\t}\n\t\t\t});\n\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ceaa9738cad9616d1831286111af106e13e0e4b","date":1114543820,"type":5,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Weight,Filter,HitCollector).mjava","pathOld":"src/java/org/apache/lucene/search/ParallelMultiSearcher#search(Query,Filter,HitCollector).mjava","sourceNew":"  /** Lower-level search API.\n   *\n   * <p>{@link HitCollector#collect(int,float)} is called for every non-zero\n   * scoring document.\n   *\n   * <p>Applications should only use this if they need <i>all</i> of the\n   * matching documents.  The high-level search API ({@link\n   * Searcher#search(Query)}) is usually more efficient, as it skips\n   * non-high-scoring hits.\n   *\n   * @param query to match documents\n   * @param filter if non-null, a bitset used to eliminate some documents\n   * @param results to receive hits\n   * \n   * TODO: parallelize this one too\n   */\n  public void search(Weight weight, Filter filter, final HitCollector results)\n    throws IOException {\n    for (int i = 0; i < searchables.length; i++) {\n\n      final int start = starts[i];\n\n      searchables[i].search(weight, filter, new HitCollector() {\n          public void collect(int doc, float score) {\n            results.collect(doc + start, score);\n          }\n        });\n\n    }\n  }\n\n","sourceOld":"  /** Lower-level search API.\n   *\n   * <p>{@link HitCollector#collect(int,float)} is called for every non-zero\n   * scoring document.\n   *\n   * <p>Applications should only use this if they need <i>all</i> of the\n   * matching documents.  The high-level search API ({@link\n   * Searcher#search(Query)}) is usually more efficient, as it skips\n   * non-high-scoring hits.\n   *\n   * @param query to match documents\n   * @param filter if non-null, a bitset used to eliminate some documents\n   * @param results to receive hits\n   * \n   * TODO: parallelize this one too\n   */\n  public void search(Query query, Filter filter, final HitCollector results)\n    throws IOException {\n    for (int i = 0; i < searchables.length; i++) {\n\n      final int start = starts[i];\n\n      searchables[i].search(query, filter, new HitCollector() {\n          public void collect(int doc, float score) {\n            results.collect(doc + start, score);\n          }\n        });\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4ceaa9738cad9616d1831286111af106e13e0e4b":["c6691cb6747f9e850337c706c06b92e9ddf816e1"],"c6691cb6747f9e850337c706c06b92e9ddf816e1":["82dc8f80042322d1c443b6c70bdec5249eb745c2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"82dc8f80042322d1c443b6c70bdec5249eb745c2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4ceaa9738cad9616d1831286111af106e13e0e4b"]},"commit2Childs":{"4ceaa9738cad9616d1831286111af106e13e0e4b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c6691cb6747f9e850337c706c06b92e9ddf816e1":["4ceaa9738cad9616d1831286111af106e13e0e4b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["82dc8f80042322d1c443b6c70bdec5249eb745c2"],"82dc8f80042322d1c443b6c70bdec5249eb745c2":["c6691cb6747f9e850337c706c06b92e9ddf816e1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}