{"path":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","commits":[{"id":"73d216e8a31fcc28595d9f9518b2f081d9379789","date":1333813682,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","pathOld":"/dev/null","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            // TODO: also look for other variants and handle them special\n            int idx = random.nextInt(tokenfilters.length);\n            try {\n              Constructor c = tokenfilters[idx].getConstructor(Version.class, TokenStream.class);\n              spec.stream = (TokenFilter) c.newInstance(TEST_VERSION_CURRENT, spec.stream);\n            } catch (NoSuchMethodException e) {\n              Constructor c = tokenfilters[idx].getConstructor(TokenStream.class);\n              spec.stream = (TokenFilter) c.newInstance(spec.stream);\n            }\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(tokenfilters[idx].toString());\n            success = true;\n          } catch (Exception e) {\n            // ignore\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a75004531a9cdf4ad1c7a295d1c822057af45b87","date":1333836028,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            // TODO: also look for other variants and handle them special\n            int idx = random.nextInt(tokenfilters.size());\n            try {\n              Constructor<? extends TokenFilter> c = tokenfilters.get(idx).getConstructor(Version.class, TokenStream.class);\n              spec.stream = c.newInstance(TEST_VERSION_CURRENT, spec.stream);\n            } catch (NoSuchMethodException e) {\n              Constructor<? extends TokenFilter> c = tokenfilters.get(idx).getConstructor(TokenStream.class);\n              spec.stream = c.newInstance(spec.stream);\n            }\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(tokenfilters.get(idx).toString());\n            success = true;\n          } catch (Exception e) {\n            // ignore\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            // TODO: also look for other variants and handle them special\n            int idx = random.nextInt(tokenfilters.length);\n            try {\n              Constructor c = tokenfilters[idx].getConstructor(Version.class, TokenStream.class);\n              spec.stream = (TokenFilter) c.newInstance(TEST_VERSION_CURRENT, spec.stream);\n            } catch (NoSuchMethodException e) {\n              Constructor c = tokenfilters[idx].getConstructor(TokenStream.class);\n              spec.stream = (TokenFilter) c.newInstance(spec.stream);\n            }\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(tokenfilters[idx].toString());\n            success = true;\n          } catch (Exception e) {\n            // ignore\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a92b21feea3b1b4d7ad5a06439333c4f757318f","date":1333977928,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n            final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n            spec.stream = ctor.newInstance(args);\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(ctor.getDeclaringClass().getName());\n            descr.append(\"(\" + Arrays.toString(args) + \")\");\n            success = true;\n          } catch (InvocationTargetException ite) {\n            final Throwable cause = ite.getCause();\n            if (cause instanceof IllegalArgumentException ||\n                cause instanceof UnsupportedOperationException) {\n              // thats ok, ignore\n              if (VERBOSE) {\n                System.err.println(\"Ignoring IAE/UOE from ctor:\");\n                cause.printStackTrace(System.err);\n              }\n            } else {\n              Rethrow.rethrow(cause);\n            }\n          } catch (IllegalAccessException iae) {\n            Rethrow.rethrow(iae);\n          } catch (InstantiationException ie) {\n            Rethrow.rethrow(ie);\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            // TODO: also look for other variants and handle them special\n            int idx = random.nextInt(tokenfilters.size());\n            try {\n              Constructor<? extends TokenFilter> c = tokenfilters.get(idx).getConstructor(Version.class, TokenStream.class);\n              spec.stream = c.newInstance(TEST_VERSION_CURRENT, spec.stream);\n            } catch (NoSuchMethodException e) {\n              Constructor<? extends TokenFilter> c = tokenfilters.get(idx).getConstructor(TokenStream.class);\n              spec.stream = c.newInstance(spec.stream);\n            }\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(tokenfilters.get(idx).toString());\n            success = true;\n          } catch (Exception e) {\n            // ignore\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1f4dc85b409fc5f00183c0cafb53ab47621e5eb","date":1333990334,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            success = true;\n            spec.stream = flt;\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n            final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n            spec.stream = ctor.newInstance(args);\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(ctor.getDeclaringClass().getName());\n            descr.append(\"(\" + Arrays.toString(args) + \")\");\n            success = true;\n          } catch (InvocationTargetException ite) {\n            final Throwable cause = ite.getCause();\n            if (cause instanceof IllegalArgumentException ||\n                cause instanceof UnsupportedOperationException) {\n              // thats ok, ignore\n              if (VERBOSE) {\n                System.err.println(\"Ignoring IAE/UOE from ctor:\");\n                cause.printStackTrace(System.err);\n              }\n            } else {\n              Rethrow.rethrow(cause);\n            }\n          } catch (IllegalAccessException iae) {\n            Rethrow.rethrow(iae);\n          } catch (InstantiationException ie) {\n            Rethrow.rethrow(ie);\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"66c70960e9f3c71ba43a0a8a00c4caded28d4dd5","date":1333990595,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        while (true) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            spec.stream = flt;\n            break;\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            success = true;\n            spec.stream = flt;\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa380b0ac7fa6c578259afbb8eaa19927570010d","date":1333998347,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n\n        // Insert ValidatingTF after each stage so we can\n        // catch problems right after the TF that \"caused\"\n        // them:\n        spec.stream = new ValidatingTokenFilter(spec.stream, \"stage \" + i);\n\n        while (true) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            spec.stream = flt;\n            break;\n          }\n        }\n      }\n\n      // Insert ValidatingTF after each stage so we can\n      // catch problems right after the TF that \"caused\"\n      // them:\n      spec.stream = new ValidatingTokenFilter(spec.stream, \"last stage\");\n\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        while (true) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            spec.stream = flt;\n            break;\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"888c2d6bca1edd8d9293631d6e1d188b036e0f05","date":1334076894,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer,boolean).mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer, boolean offsetsAreCorrect) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.offsetsAreCorrect = offsetsAreCorrect;\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n\n        // Insert ValidatingTF after each stage so we can\n        // catch problems right after the TF that \"caused\"\n        // them:\n        spec.stream = new ValidatingTokenFilter(spec.stream, \"stage \" + i, spec.offsetsAreCorrect);\n\n        while (true) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            if (brokenOffsetsComponents.contains(ctor.getDeclaringClass())) {\n              spec.offsetsAreCorrect = false;\n            }\n            spec.stream = flt;\n            break;\n          }\n        }\n      }\n\n      // Insert ValidatingTF after each stage so we can\n      // catch problems right after the TF that \"caused\"\n      // them:\n      spec.stream = new ValidatingTokenFilter(spec.stream, \"last stage\", spec.offsetsAreCorrect);\n\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n\n        // Insert ValidatingTF after each stage so we can\n        // catch problems right after the TF that \"caused\"\n        // them:\n        spec.stream = new ValidatingTokenFilter(spec.stream, \"stage \" + i);\n\n        while (true) {\n          final Constructor<? extends TokenFilter> ctor = tokenfilters.get(random.nextInt(tokenfilters.size()));\n          final Object args[] = newFilterArgs(random, spec.stream, ctor.getParameterTypes());\n          final TokenFilter flt = createComponent(ctor, args, descr);\n          if (flt != null) {\n            spec.stream = flt;\n            break;\n          }\n        }\n      }\n\n      // Insert ValidatingTF after each stage so we can\n      // catch problems right after the TF that \"caused\"\n      // them:\n      spec.stream = new ValidatingTokenFilter(spec.stream, \"last stage\");\n\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","date":1334174049,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#newFilterChain(Random,Tokenizer).mjava","sourceNew":null,"sourceOld":"    private TokenFilterSpec newFilterChain(Random random, Tokenizer tokenizer) {\n      TokenFilterSpec spec = new TokenFilterSpec();\n      spec.stream = tokenizer;\n      StringBuilder descr = new StringBuilder();\n      int numFilters = random.nextInt(5);\n      for (int i = 0; i < numFilters; i++) {\n        boolean success = false;\n        while (!success) {\n          try {\n            // TODO: also look for other variants and handle them special\n            int idx = random.nextInt(tokenfilters.size());\n            try {\n              Constructor<? extends TokenFilter> c = tokenfilters.get(idx).getConstructor(Version.class, TokenStream.class);\n              spec.stream = c.newInstance(TEST_VERSION_CURRENT, spec.stream);\n            } catch (NoSuchMethodException e) {\n              Constructor<? extends TokenFilter> c = tokenfilters.get(idx).getConstructor(TokenStream.class);\n              spec.stream = c.newInstance(spec.stream);\n            }\n            if (descr.length() > 0) {\n              descr.append(\",\");\n            }\n            descr.append(tokenfilters.get(idx).toString());\n            success = true;\n          } catch (Exception e) {\n            // ignore\n          }\n        }\n      }\n      spec.toString = descr.toString();\n      return spec;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"888c2d6bca1edd8d9293631d6e1d188b036e0f05":["aa380b0ac7fa6c578259afbb8eaa19927570010d"],"d1f4dc85b409fc5f00183c0cafb53ab47621e5eb":["5a92b21feea3b1b4d7ad5a06439333c4f757318f"],"a75004531a9cdf4ad1c7a295d1c822057af45b87":["73d216e8a31fcc28595d9f9518b2f081d9379789"],"66c70960e9f3c71ba43a0a8a00c4caded28d4dd5":["d1f4dc85b409fc5f00183c0cafb53ab47621e5eb"],"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e":["a75004531a9cdf4ad1c7a295d1c822057af45b87","888c2d6bca1edd8d9293631d6e1d188b036e0f05"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5a92b21feea3b1b4d7ad5a06439333c4f757318f":["a75004531a9cdf4ad1c7a295d1c822057af45b87"],"aa380b0ac7fa6c578259afbb8eaa19927570010d":["66c70960e9f3c71ba43a0a8a00c4caded28d4dd5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"73d216e8a31fcc28595d9f9518b2f081d9379789":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"888c2d6bca1edd8d9293631d6e1d188b036e0f05":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e"],"d1f4dc85b409fc5f00183c0cafb53ab47621e5eb":["66c70960e9f3c71ba43a0a8a00c4caded28d4dd5"],"a75004531a9cdf4ad1c7a295d1c822057af45b87":["ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e","5a92b21feea3b1b4d7ad5a06439333c4f757318f"],"66c70960e9f3c71ba43a0a8a00c4caded28d4dd5":["aa380b0ac7fa6c578259afbb8eaa19927570010d"],"ad9e3deabce40d9849c1b75ef706bfa79f4f0d1e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["73d216e8a31fcc28595d9f9518b2f081d9379789"],"5a92b21feea3b1b4d7ad5a06439333c4f757318f":["d1f4dc85b409fc5f00183c0cafb53ab47621e5eb"],"aa380b0ac7fa6c578259afbb8eaa19927570010d":["888c2d6bca1edd8d9293631d6e1d188b036e0f05"],"73d216e8a31fcc28595d9f9518b2f081d9379789":["a75004531a9cdf4ad1c7a295d1c822057af45b87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}