{"path":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","commits":[{"id":"226abb667f503323e0d9473af1883fa03ef3a3fd","date":1163596173,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Parse the Reuters SGML and index:\n     * Date, Title, Dateline, Body\n     *\n     *\n     *\n     * @param in        input file\n     * @return Lucene document\n     */\n    protected Document makeDocument(File in, String[] tags, boolean stored, boolean tokenized, boolean tfv)\n            throws Exception\n    {\n        Document doc = new Document();\n        // tag this document\n        if (tags != null)\n        {\n            for (int i = 0; i < tags.length; i++)\n            {\n                doc.add(new Field(\"tag\" + i, tags[i], stored == true ? Field.Store.YES : Field.Store.NO,\n                                  tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n            }\n        }\n        doc.add(new Field(\"file\", in.getCanonicalPath(), stored == true ? Field.Store.YES : Field.Store.NO,\n                          tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        BufferedReader reader = new BufferedReader(new FileReader(in));\n        String line = null;\n        //First line is the date, 3rd is the title, rest is body\n        String dateStr = reader.readLine();\n        reader.readLine();//skip an empty line\n        String title = reader.readLine();\n        reader.readLine();//skip an empty line\n        StringBuffer body = new StringBuffer(1024);\n        while ((line = reader.readLine()) != null)\n        {\n            body.append(line).append(' ');\n        }\n        Date date = format.parse(dateStr.trim());\n\n        doc.add(new Field(\"date\", DateTools.dateToString(date, DateTools.Resolution.SECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n        if (title != null)\n        {\n            doc.add(new Field(\"title\", title, stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n        if (body.length() > 0)\n        {\n            doc.add(new Field(\"body\", body.toString(), stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n\n        return doc;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c55a660bceaf72068ba1fbf6856388430c0a7334","date":1174007816,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","sourceNew":"    /**\n     * Parse the Reuters SGML and index:\n     * Date, Title, Dateline, Body\n     *\n     *\n     *\n     * @param in        input file\n     * @return Lucene document\n     */\n    protected Document makeDocument(File in, String[] tags, boolean stored, boolean tokenized, boolean tfv)\n            throws Exception\n    {\n        Document doc = new Document();\n        // tag this document\n        if (tags != null)\n        {\n            for (int i = 0; i < tags.length; i++)\n            {\n                doc.add(new Field(\"tag\" + i, tags[i], stored == true ? Field.Store.YES : Field.Store.NO,\n                                  tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n            }\n        }\n        doc.add(new Field(\"file\", in.getCanonicalPath(), stored == true ? Field.Store.YES : Field.Store.NO,\n                          tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        BufferedReader reader = new BufferedReader(new FileReader(in));\n        String line = null;\n        //First line is the date, 3rd is the title, rest is body\n        String dateStr = reader.readLine();\n        reader.readLine();//skip an empty line\n        String title = reader.readLine();\n        reader.readLine();//skip an empty line\n        StringBuffer body = new StringBuffer(1024);\n        while ((line = reader.readLine()) != null)\n        {\n            body.append(line).append(' ');\n        }\n        reader.close();\n        \n        Date date = format.parse(dateStr.trim());\n\n        doc.add(new Field(\"date\", DateTools.dateToString(date, DateTools.Resolution.SECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n        if (title != null)\n        {\n            doc.add(new Field(\"title\", title, stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n        if (body.length() > 0)\n        {\n            doc.add(new Field(\"body\", body.toString(), stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n\n        return doc;\n    }\n\n","sourceOld":"    /**\n     * Parse the Reuters SGML and index:\n     * Date, Title, Dateline, Body\n     *\n     *\n     *\n     * @param in        input file\n     * @return Lucene document\n     */\n    protected Document makeDocument(File in, String[] tags, boolean stored, boolean tokenized, boolean tfv)\n            throws Exception\n    {\n        Document doc = new Document();\n        // tag this document\n        if (tags != null)\n        {\n            for (int i = 0; i < tags.length; i++)\n            {\n                doc.add(new Field(\"tag\" + i, tags[i], stored == true ? Field.Store.YES : Field.Store.NO,\n                                  tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n            }\n        }\n        doc.add(new Field(\"file\", in.getCanonicalPath(), stored == true ? Field.Store.YES : Field.Store.NO,\n                          tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        BufferedReader reader = new BufferedReader(new FileReader(in));\n        String line = null;\n        //First line is the date, 3rd is the title, rest is body\n        String dateStr = reader.readLine();\n        reader.readLine();//skip an empty line\n        String title = reader.readLine();\n        reader.readLine();//skip an empty line\n        StringBuffer body = new StringBuffer(1024);\n        while ((line = reader.readLine()) != null)\n        {\n            body.append(line).append(' ');\n        }\n        Date date = format.parse(dateStr.trim());\n\n        doc.add(new Field(\"date\", DateTools.dateToString(date, DateTools.Resolution.SECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n        if (title != null)\n        {\n            doc.add(new Field(\"title\", title, stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n        if (body.length() > 0)\n        {\n            doc.add(new Field(\"body\", body.toString(), stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n\n        return doc;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a","date":1221082732,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","sourceNew":"    /**\n     * Parse the Reuters SGML and index:\n     * Date, Title, Dateline, Body\n     *\n     *\n     *\n     * @param in        input file\n     * @return Lucene document\n     */\n    protected Document makeDocument(File in, String[] tags, boolean stored, boolean tokenized, boolean tfv)\n            throws Exception\n    {\n        Document doc = new Document();\n        // tag this document\n        if (tags != null)\n        {\n            for (int i = 0; i < tags.length; i++)\n            {\n                doc.add(new Field(\"tag\" + i, tags[i], stored == true ? Field.Store.YES : Field.Store.NO,\n                                  tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n            }\n        }\n        doc.add(new Field(\"file\", in.getCanonicalPath(), stored == true ? Field.Store.YES : Field.Store.NO,\n                          tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        BufferedReader reader = new BufferedReader(new FileReader(in));\n        String line = null;\n        //First line is the date, 3rd is the title, rest is body\n        String dateStr = reader.readLine();\n        reader.readLine();//skip an empty line\n        String title = reader.readLine();\n        reader.readLine();//skip an empty line\n        StringBuffer body = new StringBuffer(1024);\n        while ((line = reader.readLine()) != null)\n        {\n            body.append(line).append(' ');\n        }\n        reader.close();\n        \n        Date date = format.parse(dateStr.trim());\n\n        doc.add(new Field(\"date\", DateTools.dateToString(date, DateTools.Resolution.SECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n        if (title != null)\n        {\n            doc.add(new Field(\"title\", title, stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n        if (body.length() > 0)\n        {\n            doc.add(new Field(\"body\", body.toString(), stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n\n        return doc;\n    }\n\n","sourceOld":"    /**\n     * Parse the Reuters SGML and index:\n     * Date, Title, Dateline, Body\n     *\n     *\n     *\n     * @param in        input file\n     * @return Lucene document\n     */\n    protected Document makeDocument(File in, String[] tags, boolean stored, boolean tokenized, boolean tfv)\n            throws Exception\n    {\n        Document doc = new Document();\n        // tag this document\n        if (tags != null)\n        {\n            for (int i = 0; i < tags.length; i++)\n            {\n                doc.add(new Field(\"tag\" + i, tags[i], stored == true ? Field.Store.YES : Field.Store.NO,\n                                  tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n            }\n        }\n        doc.add(new Field(\"file\", in.getCanonicalPath(), stored == true ? Field.Store.YES : Field.Store.NO,\n                          tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        BufferedReader reader = new BufferedReader(new FileReader(in));\n        String line = null;\n        //First line is the date, 3rd is the title, rest is body\n        String dateStr = reader.readLine();\n        reader.readLine();//skip an empty line\n        String title = reader.readLine();\n        reader.readLine();//skip an empty line\n        StringBuffer body = new StringBuffer(1024);\n        while ((line = reader.readLine()) != null)\n        {\n            body.append(line).append(' ');\n        }\n        reader.close();\n        \n        Date date = format.parse(dateStr.trim());\n\n        doc.add(new Field(\"date\", DateTools.dateToString(date, DateTools.Resolution.SECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n        if (title != null)\n        {\n            doc.add(new Field(\"title\", title, stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n        if (body.length() > 0)\n        {\n            doc.add(new Field(\"body\", body.toString(), stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.TOKENIZED : Field.Index.UN_TOKENIZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n\n        return doc;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f55f56ccbdfcad354e67291558fdec36be2341c8","date":1244730392,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/standard/StandardBenchmarker#makeDocument(File,String[],boolean,boolean,boolean).mjava","sourceNew":null,"sourceOld":"    /**\n     * Parse the Reuters SGML and index:\n     * Date, Title, Dateline, Body\n     *\n     *\n     *\n     * @param in        input file\n     * @return Lucene document\n     */\n    protected Document makeDocument(File in, String[] tags, boolean stored, boolean tokenized, boolean tfv)\n            throws Exception\n    {\n        Document doc = new Document();\n        // tag this document\n        if (tags != null)\n        {\n            for (int i = 0; i < tags.length; i++)\n            {\n                doc.add(new Field(\"tag\" + i, tags[i], stored == true ? Field.Store.YES : Field.Store.NO,\n                                  tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n            }\n        }\n        doc.add(new Field(\"file\", in.getCanonicalPath(), stored == true ? Field.Store.YES : Field.Store.NO,\n                          tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        BufferedReader reader = new BufferedReader(new FileReader(in));\n        String line = null;\n        //First line is the date, 3rd is the title, rest is body\n        String dateStr = reader.readLine();\n        reader.readLine();//skip an empty line\n        String title = reader.readLine();\n        reader.readLine();//skip an empty line\n        StringBuffer body = new StringBuffer(1024);\n        while ((line = reader.readLine()) != null)\n        {\n            body.append(line).append(' ');\n        }\n        reader.close();\n        \n        Date date = format.parse(dateStr.trim());\n\n        doc.add(new Field(\"date\", DateTools.dateToString(date, DateTools.Resolution.SECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n        if (title != null)\n        {\n            doc.add(new Field(\"title\", title, stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n        if (body.length() > 0)\n        {\n            doc.add(new Field(\"body\", body.toString(), stored == true ? Field.Store.YES : Field.Store.NO,\n                              tokenized == true ? Field.Index.ANALYZED : Field.Index.NOT_ANALYZED, tfv == true ? Field.TermVector.YES : Field.TermVector.NO));\n        }\n\n        return doc;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"226abb667f503323e0d9473af1883fa03ef3a3fd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f55f56ccbdfcad354e67291558fdec36be2341c8":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["c55a660bceaf72068ba1fbf6856388430c0a7334"],"c55a660bceaf72068ba1fbf6856388430c0a7334":["226abb667f503323e0d9473af1883fa03ef3a3fd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f55f56ccbdfcad354e67291558fdec36be2341c8"]},"commit2Childs":{"226abb667f503323e0d9473af1883fa03ef3a3fd":["c55a660bceaf72068ba1fbf6856388430c0a7334"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["226abb667f503323e0d9473af1883fa03ef3a3fd"],"f55f56ccbdfcad354e67291558fdec36be2341c8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["f55f56ccbdfcad354e67291558fdec36be2341c8"],"c55a660bceaf72068ba1fbf6856388430c0a7334":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}